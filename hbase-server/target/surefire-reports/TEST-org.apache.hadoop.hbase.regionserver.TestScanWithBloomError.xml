<?xml version="1.0" encoding="UTF-8" ?>
<testsuite failures="0" time="0.001" errors="3" skipped="0" tests="3" name="org.apache.hadoop.hbase.regionserver.TestScanWithBloomError">
  <properties>
    <property name="java.runtime.name" value="Java(TM) SE Runtime Environment"/>
    <property name="sun.boot.library.path" value="/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Libraries"/>
    <property name="java.vm.version" value="20.12-b01-434"/>
    <property name="awt.nativeDoubleBuffering" value="true"/>
    <property name="gopherProxySet" value="false"/>
    <property name="mrj.build" value="10M3909"/>
    <property name="java.vm.vendor" value="Apple Inc."/>
    <property name="java.vendor.url" value="http://www.apple.com/"/>
    <property name="path.separator" value=":"/>
    <property name="guice.disable.misplaced.annotation.check" value="true"/>
    <property name="java.vm.name" value="Java HotSpot(TM) 64-Bit Server VM"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="user.country" value="CN"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="user.dir" value="/Users/daidong/github/local/DominoHBase/hbase-server"/>
    <property name="java.runtime.version" value="1.6.0_37-b06-434-10M3909"/>
    <property name="java.awt.graphicsenv" value="apple.awt.CGraphicsEnvironment"/>
    <property name="java.endorsed.dirs" value="/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home/lib/endorsed"/>
    <property name="os.arch" value="x86_64"/>
    <property name="java.io.tmpdir" value="/var/folders/0i/0iKbaNeXF8qPmXBYB20ZzE+++TI/-Tmp-/"/>
    <property name="line.separator" value="
"/>
    <property name="java.vm.specification.vendor" value="Sun Microsystems Inc."/>
    <property name="os.name" value="Mac OS X"/>
    <property name="classworlds.conf" value="/Users/daidong/Documents/workspace/.metadata/.plugins/org.eclipse.m2e.core/launches/m2conf122008558292673198.tmp"/>
    <property name="maven.test.skip" value="true"/>
    <property name="sun.jnu.encoding" value="EUC_CN"/>
    <property name="java.library.path" value=".:/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.class.version" value="50.0"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="os.version" value="10.6.8"/>
    <property name="http.nonProxyHosts" value="local|*.local|169.254/16|*.169.254/16|douban.fm|*.douban.fm|weibo.com|*.weibo.com|ustc.edu.cn|*.ustc.edu.cn|youku.com|*.youku.com|tudou.com|*.tudou.com|56.com|*.56.com|weibo.com|*.weibo.com|sinaimg.cn|*.sinaimg.cn|sina.cn|*.sina.cn|sina.com.cn|*.sina.com.cn|sina.com|*.sina.com|google.com.hk|*.google.com.hk|qq.com|*.qq.com|taobao.com|*.taobao.com|alipay.com|*.alipay.com|360buy.com|*.360buy.com|unimip.cn|*.unimip.cn|apple.com|*.apple.com|douban.com|*.douban.com|ustcsz.edu.cn|*.ustcsz.edu.cn"/>
    <property name="user.home" value="/Users/daidong"/>
    <property name="user.timezone" value="Asia/Shanghai"/>
    <property name="java.awt.printerjob" value="apple.awt.CPrinterJob"/>
    <property name="java.specification.version" value="1.6"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="user.name" value="daidong"/>
    <property name="java.class.path" value="/Applications/Eclipse/configuration/org.eclipse.osgi/bundles/963/1/.cp/jars/plexus-classworlds-2.4.jar"/>
    <property name="java.vm.specification.version" value="1.0"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="java.home" value="/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home"/>
    <property name="sun.java.command" value="org.codehaus.plexus.classworlds.launcher.Launcher -B -Dmaven.test.skip=true package"/>
    <property name="java.specification.vendor" value="Sun Microsystems Inc."/>
    <property name="user.language" value="zh"/>
    <property name="awt.toolkit" value="apple.awt.CToolkit"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.version" value="1.6.0_37"/>
    <property name="java.ext.dirs" value="/Library/Java/Extensions:/System/Library/Java/Extensions:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home/lib/ext"/>
    <property name="sun.boot.class.path" value="/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/jsfd.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/classes.jar:/System/Library/Frameworks/JavaVM.framework/Frameworks/JavaRuntimeSupport.framework/Resources/Java/JavaRuntimeSupport.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/ui.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/laf.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/sunrsasign.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/jsse.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/jce.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/charsets.jar"/>
    <property name="java.vendor" value="Apple Inc."/>
    <property name="maven.home" value="/Users/daidong/github/local/DominoHBase/hbase-server/EMBEDDED"/>
    <property name="file.separator" value="/"/>
    <property name="java.vendor.url.bug" value="http://bugreport.apple.com/"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="mrj.version" value="1060.1.6.0_37-434"/>
    <property name="socksNonProxyHosts" value="local|*.local|169.254/16|*.169.254/16|douban.fm|*.douban.fm|weibo.com|*.weibo.com|ustc.edu.cn|*.ustc.edu.cn|youku.com|*.youku.com|tudou.com|*.tudou.com|56.com|*.56.com|weibo.com|*.weibo.com|sinaimg.cn|*.sinaimg.cn|sina.cn|*.sina.cn|sina.com.cn|*.sina.com.cn|sina.com|*.sina.com|google.com.hk|*.google.com.hk|qq.com|*.qq.com|taobao.com|*.taobao.com|alipay.com|*.alipay.com|360buy.com|*.360buy.com|unimip.cn|*.unimip.cn|apple.com|*.apple.com|douban.com|*.douban.com|ustcsz.edu.cn|*.ustcsz.edu.cn"/>
    <property name="ftp.nonProxyHosts" value="local|*.local|169.254/16|*.169.254/16|douban.fm|*.douban.fm|weibo.com|*.weibo.com|ustc.edu.cn|*.ustc.edu.cn|youku.com|*.youku.com|tudou.com|*.tudou.com|56.com|*.56.com|weibo.com|*.weibo.com|sinaimg.cn|*.sinaimg.cn|sina.cn|*.sina.cn|sina.com.cn|*.sina.com.cn|sina.com|*.sina.com|google.com.hk|*.google.com.hk|qq.com|*.qq.com|taobao.com|*.taobao.com|alipay.com|*.alipay.com|360buy.com|*.360buy.com|unimip.cn|*.unimip.cn|apple.com|*.apple.com|douban.com|*.douban.com|ustcsz.edu.cn|*.ustcsz.edu.cn"/>
    <property name="sun.cpu.isalist" value=""/>
  </properties>
  <testcase time="0.001" classname="org.apache.hadoop.hbase.regionserver.TestScanWithBloomError" name="testThreeStoreFiles[0]">
    <error type="java.lang.NullPointerException">java.lang.NullPointerException
	at org.apache.hadoop.hbase.trigger.LocalTriggerManage.containsTrigger(LocalTriggerManage.java:39)
	at org.apache.hadoop.hbase.regionserver.wal.WALDetection.checkDispatch(WALDetection.java:27)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.doWrite(FSHLog.java:1220)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.append(FSHLog.java:915)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.appendNoSync(FSHLog.java:937)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:2261)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2010)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:2465)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1935)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1883)
	at org.apache.hadoop.hbase.regionserver.TestScanWithBloomError.createStoreFile(TestScanWithBloomError.java:208)
	at org.apache.hadoop.hbase.regionserver.TestScanWithBloomError.testThreeStoreFiles(TestScanWithBloomError.java:108)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:680)
</error>
    <system-err>2013-03-06 20:00:52,695 INFO  [pool-1-thread-1] hbase.ResourceChecker(147): before: regionserver.TestScanWithBloomError#testThreeStoreFiles[0] Thread=99, OpenFileDescriptor=212, MaxFileDescriptor=1000000, ConnectionCount=1
2013-03-06 20:00:52,706 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty(&quot;hadoop.log.dir&quot;) already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir so I do NOT create it in target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41
2013-03-06 20:00:52,706 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.log.dir property value differs in configuration and system: Configuration=/Users/daidong/github/local/DominoHBase/hbase-server/../logs while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir Erasing configuration value by system value.
2013-03-06 20:00:52,706 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty(&quot;hadoop.tmp.dir&quot;) already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir so I do NOT create it in target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41
2013-03-06 20:00:52,706 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.tmp.dir property value differs in configuration and system: Configuration=/tmp/hadoop-daidong while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir Erasing configuration value by system value.
2013-03-06 20:00:52,707 INFO  [pool-1-thread-1] regionserver.HRegion(3895): creating HRegion ScanWithBloomError HTD == &apos;ScanWithBloomError&apos;, {NAME =&gt; &apos;myCF&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;NONE&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, COMPRESSION =&gt; &apos;GZ&apos;, VERSIONS =&gt; &apos;50&apos;, TTL =&gt; &apos;2147483647&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, KEEP_DELETED_CELLS =&gt; &apos;false&apos;, BLOCKSIZE =&gt; &apos;65536&apos;, ENCODE_ON_DISK =&gt; &apos;true&apos;, IN_MEMORY =&gt; &apos;false&apos;, BLOCKCACHE =&gt; &apos;true&apos;} RootDir = /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41 Table name == ScanWithBloomError
2013-03-06 20:00:52,707 INFO  [pool-1-thread-1] wal.FSHLog(333): HLog configuration: blocksize=32 MB, rollsize=30.4 MB, enabled=true, optionallogflushinternal=1000ms
2013-03-06 20:00:52,709 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2013-03-06 20:00:52,709 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(193): Path=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41/ScanWithBloomError/7b1a1d5fa8b214bc2316a7ebad15c272/.logs/hlog.1362571252708, compression=false
2013-03-06 20:00:52,710 INFO  [pool-1-thread-1] wal.FSHLog(519):  for /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41/ScanWithBloomError/7b1a1d5fa8b214bc2316a7ebad15c272/.logs/hlog.1362571252708
2013-03-06 20:00:52,710 INFO  [pool-1-thread-1] wal.FSHLog(409): FileSystem&apos;s output stream doesn&apos;t support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2013-03-06 20:00:52,710 DEBUG [pool-1-thread-1] regionserver.HRegion(495): Instantiated ScanWithBloomError,,1362571252706.7b1a1d5fa8b214bc2316a7ebad15c272.
2013-03-06 20:00:52,711 DEBUG [pool-1-thread-1] util.FSUtils(165): Creating file=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41/ScanWithBloomError/7b1a1d5fa8b214bc2316a7ebad15c272/.tmp/.regioninfo with permission=rwxrwxrwx
2013-03-06 20:00:52,714 INFO  [StoreOpenerThread-ScanWithBloomError,,1362571252706.7b1a1d5fa8b214bc2316a7ebad15c272.-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 20:00:52,715 INFO  [pool-1-thread-1] regionserver.HRegion(640): Onlined ScanWithBloomError,,1362571252706.7b1a1d5fa8b214bc2316a7ebad15c272.; next sequenceid=1
2013-03-06 20:00:52,725 DEBUG [pool-1-thread-1] regionserver.HRegion(2657): rollbackMemstore rolled back 3 keyvalues from start:0 to end:1
2013-03-06 20:00:52,728 INFO  [pool-1-thread-1] hbase.ResourceChecker(171): after: regionserver.TestScanWithBloomError#testThreeStoreFiles[0] Thread=100 (was 99) - Thread LEAK? -, OpenFileDescriptor=214 (was 212) - OpenFileDescriptor LEAK? -, MaxFileDescriptor=1000000 (was 1000000), ConnectionCount=1 (was 1)
</system-err>
  </testcase>
  <testcase time="0" classname="org.apache.hadoop.hbase.regionserver.TestScanWithBloomError" name="testThreeStoreFiles[1]">
    <error type="java.lang.NullPointerException">java.lang.NullPointerException
	at org.apache.hadoop.hbase.trigger.LocalTriggerManage.containsTrigger(LocalTriggerManage.java:39)
	at org.apache.hadoop.hbase.regionserver.wal.WALDetection.checkDispatch(WALDetection.java:27)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.doWrite(FSHLog.java:1220)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.append(FSHLog.java:915)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.appendNoSync(FSHLog.java:937)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:2261)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2010)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:2465)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1935)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1883)
	at org.apache.hadoop.hbase.regionserver.TestScanWithBloomError.createStoreFile(TestScanWithBloomError.java:208)
	at org.apache.hadoop.hbase.regionserver.TestScanWithBloomError.testThreeStoreFiles(TestScanWithBloomError.java:108)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:680)
</error>
    <system-err>2013-03-06 20:00:52,730 INFO  [pool-1-thread-1] hbase.ResourceChecker(147): before: regionserver.TestScanWithBloomError#testThreeStoreFiles[1] Thread=100, OpenFileDescriptor=214, MaxFileDescriptor=1000000, ConnectionCount=1
2013-03-06 20:00:52,731 INFO  [pool-1-thread-1] regionserver.HRegion(3895): creating HRegion ScanWithBloomError HTD == &apos;ScanWithBloomError&apos;, {NAME =&gt; &apos;myCF&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;ROW&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, COMPRESSION =&gt; &apos;GZ&apos;, VERSIONS =&gt; &apos;50&apos;, TTL =&gt; &apos;2147483647&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, KEEP_DELETED_CELLS =&gt; &apos;false&apos;, BLOCKSIZE =&gt; &apos;65536&apos;, ENCODE_ON_DISK =&gt; &apos;true&apos;, IN_MEMORY =&gt; &apos;false&apos;, BLOCKCACHE =&gt; &apos;true&apos;} RootDir = /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41 Table name == ScanWithBloomError
2013-03-06 20:00:52,731 INFO  [pool-1-thread-1] wal.FSHLog(333): HLog configuration: blocksize=32 MB, rollsize=30.4 MB, enabled=true, optionallogflushinternal=1000ms
2013-03-06 20:00:52,733 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2013-03-06 20:00:52,733 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(193): Path=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41/ScanWithBloomError/13b2d0329680048dc0b343a390b3d342/.logs/hlog.1362571252732, compression=false
2013-03-06 20:00:52,733 INFO  [pool-1-thread-1] wal.FSHLog(519):  for /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41/ScanWithBloomError/13b2d0329680048dc0b343a390b3d342/.logs/hlog.1362571252732
2013-03-06 20:00:52,734 INFO  [pool-1-thread-1] wal.FSHLog(409): FileSystem&apos;s output stream doesn&apos;t support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2013-03-06 20:00:52,734 DEBUG [pool-1-thread-1] regionserver.HRegion(495): Instantiated ScanWithBloomError,,1362571252730.13b2d0329680048dc0b343a390b3d342.
2013-03-06 20:00:52,734 DEBUG [pool-1-thread-1] util.FSUtils(165): Creating file=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41/ScanWithBloomError/13b2d0329680048dc0b343a390b3d342/.tmp/.regioninfo with permission=rwxrwxrwx
2013-03-06 20:00:52,737 INFO  [StoreOpenerThread-ScanWithBloomError,,1362571252730.13b2d0329680048dc0b343a390b3d342.-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 20:00:52,738 INFO  [pool-1-thread-1] regionserver.HRegion(640): Onlined ScanWithBloomError,,1362571252730.13b2d0329680048dc0b343a390b3d342.; next sequenceid=1
2013-03-06 20:00:52,739 DEBUG [pool-1-thread-1] regionserver.HRegion(2657): rollbackMemstore rolled back 3 keyvalues from start:0 to end:1
2013-03-06 20:00:52,742 INFO  [pool-1-thread-1] hbase.ResourceChecker(171): after: regionserver.TestScanWithBloomError#testThreeStoreFiles[1] Thread=101 (was 100) - Thread LEAK? -, OpenFileDescriptor=216 (was 214) - OpenFileDescriptor LEAK? -, MaxFileDescriptor=1000000 (was 1000000), ConnectionCount=1 (was 1)
</system-err>
  </testcase>
  <testcase time="0" classname="org.apache.hadoop.hbase.regionserver.TestScanWithBloomError" name="testThreeStoreFiles[2]">
    <error type="java.lang.NullPointerException">java.lang.NullPointerException
	at org.apache.hadoop.hbase.trigger.LocalTriggerManage.containsTrigger(LocalTriggerManage.java:39)
	at org.apache.hadoop.hbase.regionserver.wal.WALDetection.checkDispatch(WALDetection.java:27)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.doWrite(FSHLog.java:1220)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.append(FSHLog.java:915)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.appendNoSync(FSHLog.java:937)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:2261)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2010)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:2465)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1935)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1883)
	at org.apache.hadoop.hbase.regionserver.TestScanWithBloomError.createStoreFile(TestScanWithBloomError.java:208)
	at org.apache.hadoop.hbase.regionserver.TestScanWithBloomError.testThreeStoreFiles(TestScanWithBloomError.java:108)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:680)
</error>
    <system-err>2013-03-06 20:00:52,745 INFO  [pool-1-thread-1] hbase.ResourceChecker(147): before: regionserver.TestScanWithBloomError#testThreeStoreFiles[2] Thread=101, OpenFileDescriptor=216, MaxFileDescriptor=1000000, ConnectionCount=1
2013-03-06 20:00:52,746 INFO  [pool-1-thread-1] regionserver.HRegion(3895): creating HRegion ScanWithBloomError HTD == &apos;ScanWithBloomError&apos;, {NAME =&gt; &apos;myCF&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;ROWCOL&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, COMPRESSION =&gt; &apos;GZ&apos;, VERSIONS =&gt; &apos;50&apos;, TTL =&gt; &apos;2147483647&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, KEEP_DELETED_CELLS =&gt; &apos;false&apos;, BLOCKSIZE =&gt; &apos;65536&apos;, ENCODE_ON_DISK =&gt; &apos;true&apos;, IN_MEMORY =&gt; &apos;false&apos;, BLOCKCACHE =&gt; &apos;true&apos;} RootDir = /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41 Table name == ScanWithBloomError
2013-03-06 20:00:52,746 INFO  [pool-1-thread-1] wal.FSHLog(333): HLog configuration: blocksize=32 MB, rollsize=30.4 MB, enabled=true, optionallogflushinternal=1000ms
2013-03-06 20:00:52,748 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2013-03-06 20:00:52,748 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(193): Path=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41/ScanWithBloomError/f9175af129a09e6d0f89d9242c510dd9/.logs/hlog.1362571252747, compression=false
2013-03-06 20:00:52,748 INFO  [pool-1-thread-1] wal.FSHLog(519):  for /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41/ScanWithBloomError/f9175af129a09e6d0f89d9242c510dd9/.logs/hlog.1362571252747
2013-03-06 20:00:52,749 INFO  [pool-1-thread-1] wal.FSHLog(409): FileSystem&apos;s output stream doesn&apos;t support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2013-03-06 20:00:52,749 DEBUG [pool-1-thread-1] regionserver.HRegion(495): Instantiated ScanWithBloomError,,1362571252746.f9175af129a09e6d0f89d9242c510dd9.
2013-03-06 20:00:52,749 DEBUG [pool-1-thread-1] util.FSUtils(165): Creating file=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41/ScanWithBloomError/f9175af129a09e6d0f89d9242c510dd9/.tmp/.regioninfo with permission=rwxrwxrwx
2013-03-06 20:00:52,753 INFO  [StoreOpenerThread-ScanWithBloomError,,1362571252746.f9175af129a09e6d0f89d9242c510dd9.-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 20:00:52,753 INFO  [pool-1-thread-1] regionserver.HRegion(640): Onlined ScanWithBloomError,,1362571252746.f9175af129a09e6d0f89d9242c510dd9.; next sequenceid=1
2013-03-06 20:00:52,754 DEBUG [pool-1-thread-1] regionserver.HRegion(2657): rollbackMemstore rolled back 3 keyvalues from start:0 to end:1
2013-03-06 20:00:52,757 INFO  [pool-1-thread-1] hbase.ResourceChecker(171): after: regionserver.TestScanWithBloomError#testThreeStoreFiles[2] Thread=102 (was 101) - Thread LEAK? -, OpenFileDescriptor=218 (was 216) - OpenFileDescriptor LEAK? -, MaxFileDescriptor=1000000 (was 1000000), ConnectionCount=1 (was 1)
2013-03-06 20:00:52,772 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty(&quot;hadoop.log.dir&quot;) already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir so I do NOT create it in target/test-data/dd6329c7-3b63-4149-864d-87b6f16c7e50
2013-03-06 20:00:52,772 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.log.dir property value differs in configuration and system: Configuration=/Users/daidong/github/local/DominoHBase/hbase-server/../logs while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir Erasing configuration value by system value.
2013-03-06 20:00:52,772 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty(&quot;hadoop.tmp.dir&quot;) already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir so I do NOT create it in target/test-data/dd6329c7-3b63-4149-864d-87b6f16c7e50
2013-03-06 20:00:52,772 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.tmp.dir property value differs in configuration and system: Configuration=/tmp/hadoop-daidong while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir Erasing configuration value by system value.
</system-err>
  </testcase>
</testsuite>