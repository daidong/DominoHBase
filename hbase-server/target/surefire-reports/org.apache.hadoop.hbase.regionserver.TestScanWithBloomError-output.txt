2013-03-06 20:00:52,695 INFO  [pool-1-thread-1] hbase.ResourceChecker(147): before: regionserver.TestScanWithBloomError#testThreeStoreFiles[0] Thread=99, OpenFileDescriptor=212, MaxFileDescriptor=1000000, ConnectionCount=1
2013-03-06 20:00:52,706 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty("hadoop.log.dir") already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir so I do NOT create it in target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41
2013-03-06 20:00:52,706 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.log.dir property value differs in configuration and system: Configuration=/Users/daidong/github/local/DominoHBase/hbase-server/../logs while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir Erasing configuration value by system value.
2013-03-06 20:00:52,706 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty("hadoop.tmp.dir") already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir so I do NOT create it in target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41
2013-03-06 20:00:52,706 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.tmp.dir property value differs in configuration and system: Configuration=/tmp/hadoop-daidong while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir Erasing configuration value by system value.
2013-03-06 20:00:52,707 INFO  [pool-1-thread-1] regionserver.HRegion(3895): creating HRegion ScanWithBloomError HTD == 'ScanWithBloomError', {NAME => 'myCF', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION => 'GZ', VERSIONS => '50', TTL => '2147483647', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', ENCODE_ON_DISK => 'true', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41 Table name == ScanWithBloomError
2013-03-06 20:00:52,707 INFO  [pool-1-thread-1] wal.FSHLog(333): HLog configuration: blocksize=32 MB, rollsize=30.4 MB, enabled=true, optionallogflushinternal=1000ms
2013-03-06 20:00:52,709 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2013-03-06 20:00:52,709 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(193): Path=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41/ScanWithBloomError/7b1a1d5fa8b214bc2316a7ebad15c272/.logs/hlog.1362571252708, compression=false
2013-03-06 20:00:52,710 INFO  [pool-1-thread-1] wal.FSHLog(519):  for /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41/ScanWithBloomError/7b1a1d5fa8b214bc2316a7ebad15c272/.logs/hlog.1362571252708
2013-03-06 20:00:52,710 INFO  [pool-1-thread-1] wal.FSHLog(409): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2013-03-06 20:00:52,710 DEBUG [pool-1-thread-1] regionserver.HRegion(495): Instantiated ScanWithBloomError,,1362571252706.7b1a1d5fa8b214bc2316a7ebad15c272.
2013-03-06 20:00:52,711 DEBUG [pool-1-thread-1] util.FSUtils(165): Creating file=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41/ScanWithBloomError/7b1a1d5fa8b214bc2316a7ebad15c272/.tmp/.regioninfo with permission=rwxrwxrwx
2013-03-06 20:00:52,714 INFO  [StoreOpenerThread-ScanWithBloomError,,1362571252706.7b1a1d5fa8b214bc2316a7ebad15c272.-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 20:00:52,715 INFO  [pool-1-thread-1] regionserver.HRegion(640): Onlined ScanWithBloomError,,1362571252706.7b1a1d5fa8b214bc2316a7ebad15c272.; next sequenceid=1
2013-03-06 20:00:52,725 DEBUG [pool-1-thread-1] regionserver.HRegion(2657): rollbackMemstore rolled back 3 keyvalues from start:0 to end:1
2013-03-06 20:00:52,728 INFO  [pool-1-thread-1] hbase.ResourceChecker(171): after: regionserver.TestScanWithBloomError#testThreeStoreFiles[0] Thread=100 (was 99) - Thread LEAK? -, OpenFileDescriptor=214 (was 212) - OpenFileDescriptor LEAK? -, MaxFileDescriptor=1000000 (was 1000000), ConnectionCount=1 (was 1)
2013-03-06 20:00:52,730 INFO  [pool-1-thread-1] hbase.ResourceChecker(147): before: regionserver.TestScanWithBloomError#testThreeStoreFiles[1] Thread=100, OpenFileDescriptor=214, MaxFileDescriptor=1000000, ConnectionCount=1
2013-03-06 20:00:52,731 INFO  [pool-1-thread-1] regionserver.HRegion(3895): creating HRegion ScanWithBloomError HTD == 'ScanWithBloomError', {NAME => 'myCF', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', COMPRESSION => 'GZ', VERSIONS => '50', TTL => '2147483647', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', ENCODE_ON_DISK => 'true', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41 Table name == ScanWithBloomError
2013-03-06 20:00:52,731 INFO  [pool-1-thread-1] wal.FSHLog(333): HLog configuration: blocksize=32 MB, rollsize=30.4 MB, enabled=true, optionallogflushinternal=1000ms
2013-03-06 20:00:52,733 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2013-03-06 20:00:52,733 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(193): Path=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41/ScanWithBloomError/13b2d0329680048dc0b343a390b3d342/.logs/hlog.1362571252732, compression=false
2013-03-06 20:00:52,733 INFO  [pool-1-thread-1] wal.FSHLog(519):  for /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41/ScanWithBloomError/13b2d0329680048dc0b343a390b3d342/.logs/hlog.1362571252732
2013-03-06 20:00:52,734 INFO  [pool-1-thread-1] wal.FSHLog(409): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2013-03-06 20:00:52,734 DEBUG [pool-1-thread-1] regionserver.HRegion(495): Instantiated ScanWithBloomError,,1362571252730.13b2d0329680048dc0b343a390b3d342.
2013-03-06 20:00:52,734 DEBUG [pool-1-thread-1] util.FSUtils(165): Creating file=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41/ScanWithBloomError/13b2d0329680048dc0b343a390b3d342/.tmp/.regioninfo with permission=rwxrwxrwx
2013-03-06 20:00:52,737 INFO  [StoreOpenerThread-ScanWithBloomError,,1362571252730.13b2d0329680048dc0b343a390b3d342.-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 20:00:52,738 INFO  [pool-1-thread-1] regionserver.HRegion(640): Onlined ScanWithBloomError,,1362571252730.13b2d0329680048dc0b343a390b3d342.; next sequenceid=1
2013-03-06 20:00:52,739 DEBUG [pool-1-thread-1] regionserver.HRegion(2657): rollbackMemstore rolled back 3 keyvalues from start:0 to end:1
2013-03-06 20:00:52,742 INFO  [pool-1-thread-1] hbase.ResourceChecker(171): after: regionserver.TestScanWithBloomError#testThreeStoreFiles[1] Thread=101 (was 100) - Thread LEAK? -, OpenFileDescriptor=216 (was 214) - OpenFileDescriptor LEAK? -, MaxFileDescriptor=1000000 (was 1000000), ConnectionCount=1 (was 1)
2013-03-06 20:00:52,745 INFO  [pool-1-thread-1] hbase.ResourceChecker(147): before: regionserver.TestScanWithBloomError#testThreeStoreFiles[2] Thread=101, OpenFileDescriptor=216, MaxFileDescriptor=1000000, ConnectionCount=1
2013-03-06 20:00:52,746 INFO  [pool-1-thread-1] regionserver.HRegion(3895): creating HRegion ScanWithBloomError HTD == 'ScanWithBloomError', {NAME => 'myCF', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROWCOL', REPLICATION_SCOPE => '0', COMPRESSION => 'GZ', VERSIONS => '50', TTL => '2147483647', MIN_VERSIONS => '0', KEEP_DELETED_CELLS => 'false', BLOCKSIZE => '65536', ENCODE_ON_DISK => 'true', IN_MEMORY => 'false', BLOCKCACHE => 'true'} RootDir = /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41 Table name == ScanWithBloomError
2013-03-06 20:00:52,746 INFO  [pool-1-thread-1] wal.FSHLog(333): HLog configuration: blocksize=32 MB, rollsize=30.4 MB, enabled=true, optionallogflushinternal=1000ms
2013-03-06 20:00:52,748 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2013-03-06 20:00:52,748 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(193): Path=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41/ScanWithBloomError/f9175af129a09e6d0f89d9242c510dd9/.logs/hlog.1362571252747, compression=false
2013-03-06 20:00:52,748 INFO  [pool-1-thread-1] wal.FSHLog(519):  for /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41/ScanWithBloomError/f9175af129a09e6d0f89d9242c510dd9/.logs/hlog.1362571252747
2013-03-06 20:00:52,749 INFO  [pool-1-thread-1] wal.FSHLog(409): FileSystem's output stream doesn't support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2013-03-06 20:00:52,749 DEBUG [pool-1-thread-1] regionserver.HRegion(495): Instantiated ScanWithBloomError,,1362571252746.f9175af129a09e6d0f89d9242c510dd9.
2013-03-06 20:00:52,749 DEBUG [pool-1-thread-1] util.FSUtils(165): Creating file=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/297aabdb-207d-44b4-8c8b-6ca8ba1fce41/ScanWithBloomError/f9175af129a09e6d0f89d9242c510dd9/.tmp/.regioninfo with permission=rwxrwxrwx
2013-03-06 20:00:52,753 INFO  [StoreOpenerThread-ScanWithBloomError,,1362571252746.f9175af129a09e6d0f89d9242c510dd9.-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 20:00:52,753 INFO  [pool-1-thread-1] regionserver.HRegion(640): Onlined ScanWithBloomError,,1362571252746.f9175af129a09e6d0f89d9242c510dd9.; next sequenceid=1
2013-03-06 20:00:52,754 DEBUG [pool-1-thread-1] regionserver.HRegion(2657): rollbackMemstore rolled back 3 keyvalues from start:0 to end:1
2013-03-06 20:00:52,757 INFO  [pool-1-thread-1] hbase.ResourceChecker(171): after: regionserver.TestScanWithBloomError#testThreeStoreFiles[2] Thread=102 (was 101) - Thread LEAK? -, OpenFileDescriptor=218 (was 216) - OpenFileDescriptor LEAK? -, MaxFileDescriptor=1000000 (was 1000000), ConnectionCount=1 (was 1)
2013-03-06 20:00:52,772 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty("hadoop.log.dir") already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir so I do NOT create it in target/test-data/dd6329c7-3b63-4149-864d-87b6f16c7e50
2013-03-06 20:00:52,772 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.log.dir property value differs in configuration and system: Configuration=/Users/daidong/github/local/DominoHBase/hbase-server/../logs while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir Erasing configuration value by system value.
2013-03-06 20:00:52,772 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty("hadoop.tmp.dir") already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir so I do NOT create it in target/test-data/dd6329c7-3b63-4149-864d-87b6f16c7e50
2013-03-06 20:00:52,772 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.tmp.dir property value differs in configuration and system: Configuration=/tmp/hadoop-daidong while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir Erasing configuration value by system value.
