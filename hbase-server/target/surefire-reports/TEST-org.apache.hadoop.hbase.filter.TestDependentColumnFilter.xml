<?xml version="1.0" encoding="UTF-8" ?>
<testsuite failures="0" time="0.001" errors="2" skipped="0" tests="2" name="org.apache.hadoop.hbase.filter.TestDependentColumnFilter">
  <properties>
    <property name="java.runtime.name" value="Java(TM) SE Runtime Environment"/>
    <property name="sun.boot.library.path" value="/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Libraries"/>
    <property name="java.vm.version" value="20.12-b01-434"/>
    <property name="awt.nativeDoubleBuffering" value="true"/>
    <property name="gopherProxySet" value="false"/>
    <property name="mrj.build" value="10M3909"/>
    <property name="java.vm.vendor" value="Apple Inc."/>
    <property name="java.vendor.url" value="http://www.apple.com/"/>
    <property name="path.separator" value=":"/>
    <property name="guice.disable.misplaced.annotation.check" value="true"/>
    <property name="java.vm.name" value="Java HotSpot(TM) 64-Bit Server VM"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="user.country" value="CN"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="user.dir" value="/Users/daidong/github/local/DominoHBase/hbase-server"/>
    <property name="java.runtime.version" value="1.6.0_37-b06-434-10M3909"/>
    <property name="java.awt.graphicsenv" value="apple.awt.CGraphicsEnvironment"/>
    <property name="java.endorsed.dirs" value="/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home/lib/endorsed"/>
    <property name="os.arch" value="x86_64"/>
    <property name="java.io.tmpdir" value="/var/folders/0i/0iKbaNeXF8qPmXBYB20ZzE+++TI/-Tmp-/"/>
    <property name="line.separator" value="
"/>
    <property name="java.vm.specification.vendor" value="Sun Microsystems Inc."/>
    <property name="os.name" value="Mac OS X"/>
    <property name="classworlds.conf" value="/Users/daidong/Documents/workspace/.metadata/.plugins/org.eclipse.m2e.core/launches/m2conf122008558292673198.tmp"/>
    <property name="maven.test.skip" value="true"/>
    <property name="sun.jnu.encoding" value="EUC_CN"/>
    <property name="java.library.path" value=".:/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.class.version" value="50.0"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="os.version" value="10.6.8"/>
    <property name="http.nonProxyHosts" value="local|*.local|169.254/16|*.169.254/16|douban.fm|*.douban.fm|weibo.com|*.weibo.com|ustc.edu.cn|*.ustc.edu.cn|youku.com|*.youku.com|tudou.com|*.tudou.com|56.com|*.56.com|weibo.com|*.weibo.com|sinaimg.cn|*.sinaimg.cn|sina.cn|*.sina.cn|sina.com.cn|*.sina.com.cn|sina.com|*.sina.com|google.com.hk|*.google.com.hk|qq.com|*.qq.com|taobao.com|*.taobao.com|alipay.com|*.alipay.com|360buy.com|*.360buy.com|unimip.cn|*.unimip.cn|apple.com|*.apple.com|douban.com|*.douban.com|ustcsz.edu.cn|*.ustcsz.edu.cn"/>
    <property name="user.home" value="/Users/daidong"/>
    <property name="user.timezone" value="Asia/Shanghai"/>
    <property name="java.awt.printerjob" value="apple.awt.CPrinterJob"/>
    <property name="java.specification.version" value="1.6"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="user.name" value="daidong"/>
    <property name="java.class.path" value="/Applications/Eclipse/configuration/org.eclipse.osgi/bundles/963/1/.cp/jars/plexus-classworlds-2.4.jar"/>
    <property name="java.vm.specification.version" value="1.0"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="java.home" value="/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home"/>
    <property name="sun.java.command" value="org.codehaus.plexus.classworlds.launcher.Launcher -B -Dmaven.test.skip=true package"/>
    <property name="java.specification.vendor" value="Sun Microsystems Inc."/>
    <property name="user.language" value="zh"/>
    <property name="awt.toolkit" value="apple.awt.CToolkit"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.version" value="1.6.0_37"/>
    <property name="java.ext.dirs" value="/Library/Java/Extensions:/System/Library/Java/Extensions:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home/lib/ext"/>
    <property name="sun.boot.class.path" value="/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/jsfd.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/classes.jar:/System/Library/Frameworks/JavaVM.framework/Frameworks/JavaRuntimeSupport.framework/Resources/Java/JavaRuntimeSupport.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/ui.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/laf.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/sunrsasign.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/jsse.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/jce.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/charsets.jar"/>
    <property name="java.vendor" value="Apple Inc."/>
    <property name="maven.home" value="/Users/daidong/github/local/DominoHBase/hbase-server/EMBEDDED"/>
    <property name="file.separator" value="/"/>
    <property name="java.vendor.url.bug" value="http://bugreport.apple.com/"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="mrj.version" value="1060.1.6.0_37-434"/>
    <property name="socksNonProxyHosts" value="local|*.local|169.254/16|*.169.254/16|douban.fm|*.douban.fm|weibo.com|*.weibo.com|ustc.edu.cn|*.ustc.edu.cn|youku.com|*.youku.com|tudou.com|*.tudou.com|56.com|*.56.com|weibo.com|*.weibo.com|sinaimg.cn|*.sinaimg.cn|sina.cn|*.sina.cn|sina.com.cn|*.sina.com.cn|sina.com|*.sina.com|google.com.hk|*.google.com.hk|qq.com|*.qq.com|taobao.com|*.taobao.com|alipay.com|*.alipay.com|360buy.com|*.360buy.com|unimip.cn|*.unimip.cn|apple.com|*.apple.com|douban.com|*.douban.com|ustcsz.edu.cn|*.ustcsz.edu.cn"/>
    <property name="ftp.nonProxyHosts" value="local|*.local|169.254/16|*.169.254/16|douban.fm|*.douban.fm|weibo.com|*.weibo.com|ustc.edu.cn|*.ustc.edu.cn|youku.com|*.youku.com|tudou.com|*.tudou.com|56.com|*.56.com|weibo.com|*.weibo.com|sinaimg.cn|*.sinaimg.cn|sina.cn|*.sina.cn|sina.com.cn|*.sina.com.cn|sina.com|*.sina.com|google.com.hk|*.google.com.hk|qq.com|*.qq.com|taobao.com|*.taobao.com|alipay.com|*.alipay.com|360buy.com|*.360buy.com|unimip.cn|*.unimip.cn|apple.com|*.apple.com|douban.com|*.douban.com|ustcsz.edu.cn|*.ustcsz.edu.cn"/>
    <property name="sun.cpu.isalist" value=""/>
  </properties>
  <testcase time="0" classname="org.apache.hadoop.hbase.filter.TestDependentColumnFilter" name="testScans">
    <error type="java.lang.NullPointerException">java.lang.NullPointerException
	at org.apache.hadoop.hbase.trigger.LocalTriggerManage.containsTrigger(LocalTriggerManage.java:39)
	at org.apache.hadoop.hbase.regionserver.wal.WALDetection.checkDispatch(WALDetection.java:27)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.doWrite(FSHLog.java:1220)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.append(FSHLog.java:915)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.appendNoSync(FSHLog.java:937)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:2261)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2010)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:2465)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1935)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1883)
	at org.apache.hadoop.hbase.filter.TestDependentColumnFilter.addData(TestDependentColumnFilter.java:100)
	at org.apache.hadoop.hbase.filter.TestDependentColumnFilter.setUp(TestDependentColumnFilter.java:79)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:680)
</error>
    <system-err>2013-03-06 19:59:25,515 INFO  [pool-1-thread-1] hbase.ResourceChecker(147): before: filter.TestDependentColumnFilter#testScans Thread=12, OpenFileDescriptor=114, MaxFileDescriptor=1000000, ConnectionCount=0
2013-03-06 19:59:25,516 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty(&quot;hadoop.log.dir&quot;) already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir so I do NOT create it in target/test-data/486508b1-b43d-4748-b92e-290ea04598f9
2013-03-06 19:59:25,516 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.log.dir property value differs in configuration and system: Configuration=/Users/daidong/github/local/DominoHBase/hbase-server/../logs while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir Erasing configuration value by system value.
2013-03-06 19:59:25,516 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty(&quot;hadoop.tmp.dir&quot;) already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir so I do NOT create it in target/test-data/486508b1-b43d-4748-b92e-290ea04598f9
2013-03-06 19:59:25,516 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.tmp.dir property value differs in configuration and system: Configuration=/tmp/hadoop-daidong while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir Erasing configuration value by system value.
2013-03-06 19:59:25,517 INFO  [pool-1-thread-1] regionserver.HRegion(3895): creating HRegion org.apache.hadoop.hbase.filter.TestDependentColumnFilter HTD == &apos;org.apache.hadoop.hbase.filter.TestDependentColumnFilter&apos;, {NAME =&gt; &apos;familyOne&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;NONE&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, COMPRESSION =&gt; &apos;NONE&apos;, VERSIONS =&gt; &apos;3&apos;, TTL =&gt; &apos;2147483647&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, KEEP_DELETED_CELLS =&gt; &apos;false&apos;, BLOCKSIZE =&gt; &apos;65536&apos;, ENCODE_ON_DISK =&gt; &apos;true&apos;, IN_MEMORY =&gt; &apos;false&apos;, BLOCKCACHE =&gt; &apos;true&apos;}, {NAME =&gt; &apos;familyTwo&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;NONE&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, COMPRESSION =&gt; &apos;NONE&apos;, VERSIONS =&gt; &apos;3&apos;, TTL =&gt; &apos;2147483647&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, KEEP_DELETED_CELLS =&gt; &apos;false&apos;, BLOCKSIZE =&gt; &apos;65536&apos;, ENCODE_ON_DISK =&gt; &apos;true&apos;, IN_MEMORY =&gt; &apos;false&apos;, BLOCKCACHE =&gt; &apos;true&apos;} RootDir = /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/486508b1-b43d-4748-b92e-290ea04598f9 Table name == org.apache.hadoop.hbase.filter.TestDependentColumnFilter
2013-03-06 19:59:25,518 INFO  [pool-1-thread-1] wal.FSHLog(333): HLog configuration: blocksize=32 MB, rollsize=30.4 MB, enabled=true, optionallogflushinternal=1000ms
2013-03-06 19:59:25,521 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2013-03-06 19:59:25,521 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(193): Path=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/486508b1-b43d-4748-b92e-290ea04598f9/org.apache.hadoop.hbase.filter.TestDependentColumnFilter/f7e7c746410a0825baacb86765f500d0/.logs/hlog.1362571165519, compression=false
2013-03-06 19:59:25,521 INFO  [pool-1-thread-1] wal.FSHLog(519):  for /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/486508b1-b43d-4748-b92e-290ea04598f9/org.apache.hadoop.hbase.filter.TestDependentColumnFilter/f7e7c746410a0825baacb86765f500d0/.logs/hlog.1362571165519
2013-03-06 19:59:25,522 INFO  [pool-1-thread-1] wal.FSHLog(409): FileSystem&apos;s output stream doesn&apos;t support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2013-03-06 19:59:25,522 DEBUG [pool-1-thread-1] regionserver.HRegion(495): Instantiated org.apache.hadoop.hbase.filter.TestDependentColumnFilter,,1362571165515.f7e7c746410a0825baacb86765f500d0.
2013-03-06 19:59:25,523 DEBUG [pool-1-thread-1] util.FSUtils(165): Creating file=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/486508b1-b43d-4748-b92e-290ea04598f9/org.apache.hadoop.hbase.filter.TestDependentColumnFilter/f7e7c746410a0825baacb86765f500d0/.tmp/.regioninfo with permission=rwxrwxrwx
2013-03-06 19:59:25,533 INFO  [StoreOpenerThread-org.apache.hadoop.hbase.filter.TestDependentColumnFilter,,1362571165515.f7e7c746410a0825baacb86765f500d0.-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 19:59:25,541 INFO  [StoreOpenerThread-org.apache.hadoop.hbase.filter.TestDependentColumnFilter,,1362571165515.f7e7c746410a0825baacb86765f500d0.-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 19:59:25,542 INFO  [pool-1-thread-1] regionserver.HRegion(640): Onlined org.apache.hadoop.hbase.filter.TestDependentColumnFilter,,1362571165515.f7e7c746410a0825baacb86765f500d0.; next sequenceid=1
2013-03-06 19:59:25,548 DEBUG [pool-1-thread-1] regionserver.HRegion(2657): rollbackMemstore rolled back 5 keyvalues from start:0 to end:1
2013-03-06 19:59:25,549 DEBUG [pool-1-thread-1] regionserver.HRegion(975): Closing org.apache.hadoop.hbase.filter.TestDependentColumnFilter,,1362571165515.f7e7c746410a0825baacb86765f500d0.: disabling compactions &amp; flushes
2013-03-06 19:59:25,549 DEBUG [pool-1-thread-1] regionserver.HRegion(997): Updates disabled for region org.apache.hadoop.hbase.filter.TestDependentColumnFilter,,1362571165515.f7e7c746410a0825baacb86765f500d0.
2013-03-06 19:59:25,549 INFO  [StoreCloserThread-org.apache.hadoop.hbase.filter.TestDependentColumnFilter,,1362571165515.f7e7c746410a0825baacb86765f500d0.-1] regionserver.HStore(681): Closed familyOne
2013-03-06 19:59:25,550 INFO  [StoreCloserThread-org.apache.hadoop.hbase.filter.TestDependentColumnFilter,,1362571165515.f7e7c746410a0825baacb86765f500d0.-1] regionserver.HStore(681): Closed familyTwo
2013-03-06 19:59:25,550 INFO  [pool-1-thread-1] regionserver.HRegion(1050): Closed org.apache.hadoop.hbase.filter.TestDependentColumnFilter,,1362571165515.f7e7c746410a0825baacb86765f500d0.
2013-03-06 19:59:25,550 INFO  [pool-1-thread-1.logSyncer] wal.FSHLog$LogSyncer(998): pool-1-thread-1.logSyncer exiting
2013-03-06 19:59:25,550 DEBUG [pool-1-thread-1] wal.FSHLog(802): closing hlog writer in /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/486508b1-b43d-4748-b92e-290ea04598f9/org.apache.hadoop.hbase.filter.TestDependentColumnFilter/f7e7c746410a0825baacb86765f500d0/.logs
2013-03-06 19:59:25,552 DEBUG [pool-1-thread-1] wal.FSHLog(774): Moved 1 log files to /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/486508b1-b43d-4748-b92e-290ea04598f9/org.apache.hadoop.hbase.filter.TestDependentColumnFilter/f7e7c746410a0825baacb86765f500d0/.oldlogs
2013-03-06 19:59:25,589 INFO  [pool-1-thread-1] hbase.ResourceChecker(171): after: filter.TestDependentColumnFilter#testScans Thread=12 (was 12), OpenFileDescriptor=114 (was 114), MaxFileDescriptor=1000000 (was 1000000), ConnectionCount=0 (was 0)
</system-err>
  </testcase>
  <testcase time="0.001" classname="org.apache.hadoop.hbase.filter.TestDependentColumnFilter" name="testFilterDropping">
    <error type="java.lang.NullPointerException">java.lang.NullPointerException
	at org.apache.hadoop.hbase.trigger.LocalTriggerManage.containsTrigger(LocalTriggerManage.java:39)
	at org.apache.hadoop.hbase.regionserver.wal.WALDetection.checkDispatch(WALDetection.java:27)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.doWrite(FSHLog.java:1220)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.append(FSHLog.java:915)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.appendNoSync(FSHLog.java:937)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:2261)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2010)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:2465)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1935)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:1883)
	at org.apache.hadoop.hbase.filter.TestDependentColumnFilter.addData(TestDependentColumnFilter.java:100)
	at org.apache.hadoop.hbase.filter.TestDependentColumnFilter.setUp(TestDependentColumnFilter.java:79)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:680)
</error>
    <system-err>2013-03-06 19:59:25,590 INFO  [pool-1-thread-1] hbase.ResourceChecker(147): before: filter.TestDependentColumnFilter#testFilterDropping Thread=12, OpenFileDescriptor=114, MaxFileDescriptor=1000000, ConnectionCount=0
2013-03-06 19:59:25,591 INFO  [pool-1-thread-1] regionserver.HRegion(3895): creating HRegion org.apache.hadoop.hbase.filter.TestDependentColumnFilter HTD == &apos;org.apache.hadoop.hbase.filter.TestDependentColumnFilter&apos;, {NAME =&gt; &apos;familyOne&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;NONE&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, COMPRESSION =&gt; &apos;NONE&apos;, VERSIONS =&gt; &apos;3&apos;, TTL =&gt; &apos;2147483647&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, KEEP_DELETED_CELLS =&gt; &apos;false&apos;, BLOCKSIZE =&gt; &apos;65536&apos;, ENCODE_ON_DISK =&gt; &apos;true&apos;, IN_MEMORY =&gt; &apos;false&apos;, BLOCKCACHE =&gt; &apos;true&apos;}, {NAME =&gt; &apos;familyTwo&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;NONE&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, COMPRESSION =&gt; &apos;NONE&apos;, VERSIONS =&gt; &apos;3&apos;, TTL =&gt; &apos;2147483647&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, KEEP_DELETED_CELLS =&gt; &apos;false&apos;, BLOCKSIZE =&gt; &apos;65536&apos;, ENCODE_ON_DISK =&gt; &apos;true&apos;, IN_MEMORY =&gt; &apos;false&apos;, BLOCKCACHE =&gt; &apos;true&apos;} RootDir = /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/486508b1-b43d-4748-b92e-290ea04598f9 Table name == org.apache.hadoop.hbase.filter.TestDependentColumnFilter
2013-03-06 19:59:25,592 INFO  [pool-1-thread-1] wal.FSHLog(333): HLog configuration: blocksize=32 MB, rollsize=30.4 MB, enabled=true, optionallogflushinternal=1000ms
2013-03-06 19:59:25,597 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2013-03-06 19:59:25,598 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(193): Path=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/486508b1-b43d-4748-b92e-290ea04598f9/org.apache.hadoop.hbase.filter.TestDependentColumnFilter/3e8a02fc695362f72d89501dc00c5b30/.logs/hlog.1362571165593, compression=false
2013-03-06 19:59:25,598 INFO  [pool-1-thread-1] wal.FSHLog(519):  for /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/486508b1-b43d-4748-b92e-290ea04598f9/org.apache.hadoop.hbase.filter.TestDependentColumnFilter/3e8a02fc695362f72d89501dc00c5b30/.logs/hlog.1362571165593
2013-03-06 19:59:25,599 INFO  [pool-1-thread-1] wal.FSHLog(409): FileSystem&apos;s output stream doesn&apos;t support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2013-03-06 19:59:25,600 DEBUG [pool-1-thread-1] regionserver.HRegion(495): Instantiated org.apache.hadoop.hbase.filter.TestDependentColumnFilter,,1362571165590.3e8a02fc695362f72d89501dc00c5b30.
2013-03-06 19:59:25,600 DEBUG [pool-1-thread-1] util.FSUtils(165): Creating file=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/486508b1-b43d-4748-b92e-290ea04598f9/org.apache.hadoop.hbase.filter.TestDependentColumnFilter/3e8a02fc695362f72d89501dc00c5b30/.tmp/.regioninfo with permission=rwxrwxrwx
2013-03-06 19:59:25,623 INFO  [StoreOpenerThread-org.apache.hadoop.hbase.filter.TestDependentColumnFilter,,1362571165590.3e8a02fc695362f72d89501dc00c5b30.-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 19:59:25,637 INFO  [StoreOpenerThread-org.apache.hadoop.hbase.filter.TestDependentColumnFilter,,1362571165590.3e8a02fc695362f72d89501dc00c5b30.-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 19:59:25,638 INFO  [pool-1-thread-1] regionserver.HRegion(640): Onlined org.apache.hadoop.hbase.filter.TestDependentColumnFilter,,1362571165590.3e8a02fc695362f72d89501dc00c5b30.; next sequenceid=1
2013-03-06 19:59:25,648 DEBUG [pool-1-thread-1] regionserver.HRegion(2657): rollbackMemstore rolled back 5 keyvalues from start:0 to end:1
2013-03-06 19:59:25,648 DEBUG [pool-1-thread-1] regionserver.HRegion(975): Closing org.apache.hadoop.hbase.filter.TestDependentColumnFilter,,1362571165590.3e8a02fc695362f72d89501dc00c5b30.: disabling compactions &amp; flushes
2013-03-06 19:59:25,648 DEBUG [pool-1-thread-1] regionserver.HRegion(997): Updates disabled for region org.apache.hadoop.hbase.filter.TestDependentColumnFilter,,1362571165590.3e8a02fc695362f72d89501dc00c5b30.
2013-03-06 19:59:25,649 INFO  [StoreCloserThread-org.apache.hadoop.hbase.filter.TestDependentColumnFilter,,1362571165590.3e8a02fc695362f72d89501dc00c5b30.-1] regionserver.HStore(681): Closed familyOne
2013-03-06 19:59:25,649 INFO  [StoreCloserThread-org.apache.hadoop.hbase.filter.TestDependentColumnFilter,,1362571165590.3e8a02fc695362f72d89501dc00c5b30.-1] regionserver.HStore(681): Closed familyTwo
2013-03-06 19:59:25,651 INFO  [pool-1-thread-1] regionserver.HRegion(1050): Closed org.apache.hadoop.hbase.filter.TestDependentColumnFilter,,1362571165590.3e8a02fc695362f72d89501dc00c5b30.
2013-03-06 19:59:25,652 INFO  [pool-1-thread-1.logSyncer] wal.FSHLog$LogSyncer(998): pool-1-thread-1.logSyncer exiting
2013-03-06 19:59:25,652 DEBUG [pool-1-thread-1] wal.FSHLog(802): closing hlog writer in /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/486508b1-b43d-4748-b92e-290ea04598f9/org.apache.hadoop.hbase.filter.TestDependentColumnFilter/3e8a02fc695362f72d89501dc00c5b30/.logs
2013-03-06 19:59:25,653 DEBUG [pool-1-thread-1] wal.FSHLog(774): Moved 1 log files to /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/486508b1-b43d-4748-b92e-290ea04598f9/org.apache.hadoop.hbase.filter.TestDependentColumnFilter/3e8a02fc695362f72d89501dc00c5b30/.oldlogs
2013-03-06 19:59:25,654 INFO  [pool-1-thread-1] hbase.ResourceChecker(171): after: filter.TestDependentColumnFilter#testFilterDropping Thread=12 (was 12), OpenFileDescriptor=114 (was 114), MaxFileDescriptor=1000000 (was 1000000), ConnectionCount=0 (was 0)
</system-err>
  </testcase>
</testsuite>