<?xml version="1.0" encoding="UTF-8" ?>
<testsuite failures="0" time="0.003" errors="6" skipped="0" tests="6" name="org.apache.hadoop.hbase.master.TestCatalogJanitor">
  <properties>
    <property name="java.runtime.name" value="Java(TM) SE Runtime Environment"/>
    <property name="sun.boot.library.path" value="/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Libraries"/>
    <property name="java.vm.version" value="20.12-b01-434"/>
    <property name="awt.nativeDoubleBuffering" value="true"/>
    <property name="gopherProxySet" value="false"/>
    <property name="mrj.build" value="10M3909"/>
    <property name="java.vm.vendor" value="Apple Inc."/>
    <property name="java.vendor.url" value="http://www.apple.com/"/>
    <property name="path.separator" value=":"/>
    <property name="guice.disable.misplaced.annotation.check" value="true"/>
    <property name="java.vm.name" value="Java HotSpot(TM) 64-Bit Server VM"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="user.country" value="CN"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="user.dir" value="/Users/daidong/github/local/DominoHBase/hbase-server"/>
    <property name="java.runtime.version" value="1.6.0_37-b06-434-10M3909"/>
    <property name="java.awt.graphicsenv" value="apple.awt.CGraphicsEnvironment"/>
    <property name="java.endorsed.dirs" value="/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home/lib/endorsed"/>
    <property name="os.arch" value="x86_64"/>
    <property name="java.io.tmpdir" value="/var/folders/0i/0iKbaNeXF8qPmXBYB20ZzE+++TI/-Tmp-/"/>
    <property name="line.separator" value="
"/>
    <property name="java.vm.specification.vendor" value="Sun Microsystems Inc."/>
    <property name="os.name" value="Mac OS X"/>
    <property name="classworlds.conf" value="/Users/daidong/Documents/workspace/.metadata/.plugins/org.eclipse.m2e.core/launches/m2conf122008558292673198.tmp"/>
    <property name="maven.test.skip" value="true"/>
    <property name="sun.jnu.encoding" value="EUC_CN"/>
    <property name="java.library.path" value=".:/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.class.version" value="50.0"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="os.version" value="10.6.8"/>
    <property name="http.nonProxyHosts" value="local|*.local|169.254/16|*.169.254/16|douban.fm|*.douban.fm|weibo.com|*.weibo.com|ustc.edu.cn|*.ustc.edu.cn|youku.com|*.youku.com|tudou.com|*.tudou.com|56.com|*.56.com|weibo.com|*.weibo.com|sinaimg.cn|*.sinaimg.cn|sina.cn|*.sina.cn|sina.com.cn|*.sina.com.cn|sina.com|*.sina.com|google.com.hk|*.google.com.hk|qq.com|*.qq.com|taobao.com|*.taobao.com|alipay.com|*.alipay.com|360buy.com|*.360buy.com|unimip.cn|*.unimip.cn|apple.com|*.apple.com|douban.com|*.douban.com|ustcsz.edu.cn|*.ustcsz.edu.cn"/>
    <property name="user.home" value="/Users/daidong"/>
    <property name="user.timezone" value="Asia/Shanghai"/>
    <property name="java.awt.printerjob" value="apple.awt.CPrinterJob"/>
    <property name="java.specification.version" value="1.6"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="user.name" value="daidong"/>
    <property name="java.class.path" value="/Applications/Eclipse/configuration/org.eclipse.osgi/bundles/963/1/.cp/jars/plexus-classworlds-2.4.jar"/>
    <property name="java.vm.specification.version" value="1.0"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="java.home" value="/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home"/>
    <property name="sun.java.command" value="org.codehaus.plexus.classworlds.launcher.Launcher -B -Dmaven.test.skip=true package"/>
    <property name="java.specification.vendor" value="Sun Microsystems Inc."/>
    <property name="user.language" value="zh"/>
    <property name="awt.toolkit" value="apple.awt.CToolkit"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.version" value="1.6.0_37"/>
    <property name="java.ext.dirs" value="/Library/Java/Extensions:/System/Library/Java/Extensions:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Home/lib/ext"/>
    <property name="sun.boot.class.path" value="/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/jsfd.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/classes.jar:/System/Library/Frameworks/JavaVM.framework/Frameworks/JavaRuntimeSupport.framework/Resources/Java/JavaRuntimeSupport.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/ui.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/laf.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/sunrsasign.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/jsse.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/jce.jar:/System/Library/Java/JavaVirtualMachines/1.6.0.jdk/Contents/Classes/charsets.jar"/>
    <property name="java.vendor" value="Apple Inc."/>
    <property name="maven.home" value="/Users/daidong/github/local/DominoHBase/hbase-server/EMBEDDED"/>
    <property name="file.separator" value="/"/>
    <property name="java.vendor.url.bug" value="http://bugreport.apple.com/"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="mrj.version" value="1060.1.6.0_37-434"/>
    <property name="socksNonProxyHosts" value="local|*.local|169.254/16|*.169.254/16|douban.fm|*.douban.fm|weibo.com|*.weibo.com|ustc.edu.cn|*.ustc.edu.cn|youku.com|*.youku.com|tudou.com|*.tudou.com|56.com|*.56.com|weibo.com|*.weibo.com|sinaimg.cn|*.sinaimg.cn|sina.cn|*.sina.cn|sina.com.cn|*.sina.com.cn|sina.com|*.sina.com|google.com.hk|*.google.com.hk|qq.com|*.qq.com|taobao.com|*.taobao.com|alipay.com|*.alipay.com|360buy.com|*.360buy.com|unimip.cn|*.unimip.cn|apple.com|*.apple.com|douban.com|*.douban.com|ustcsz.edu.cn|*.ustcsz.edu.cn"/>
    <property name="ftp.nonProxyHosts" value="local|*.local|169.254/16|*.169.254/16|douban.fm|*.douban.fm|weibo.com|*.weibo.com|ustc.edu.cn|*.ustc.edu.cn|youku.com|*.youku.com|tudou.com|*.tudou.com|56.com|*.56.com|weibo.com|*.weibo.com|sinaimg.cn|*.sinaimg.cn|sina.cn|*.sina.cn|sina.com.cn|*.sina.com.cn|sina.com|*.sina.com|google.com.hk|*.google.com.hk|qq.com|*.qq.com|taobao.com|*.taobao.com|alipay.com|*.alipay.com|360buy.com|*.360buy.com|unimip.cn|*.unimip.cn|apple.com|*.apple.com|douban.com|*.douban.com|ustcsz.edu.cn|*.ustcsz.edu.cn"/>
    <property name="sun.cpu.isalist" value=""/>
  </properties>
  <testcase time="0" classname="org.apache.hadoop.hbase.master.TestCatalogJanitor" name="testCleanParent">
    <error type="java.lang.NullPointerException">java.lang.NullPointerException
	at org.apache.hadoop.hbase.trigger.LocalTriggerManage.containsTrigger(LocalTriggerManage.java:39)
	at org.apache.hadoop.hbase.regionserver.wal.WALDetection.checkDispatch(WALDetection.java:27)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.doWrite(FSHLog.java:1220)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.append(FSHLog.java:915)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.appendNoSync(FSHLog.java:937)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:2261)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2010)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:2465)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:2580)
	at org.apache.hadoop.hbase.regionserver.HRegion.addRegionToMETA(HRegion.java:4071)
	at org.apache.hadoop.hbase.master.MasterFileSystem.bootstrap(MasterFileSystem.java:461)
	at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:432)
	at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:147)
	at org.apache.hadoop.hbase.master.MasterFileSystem.&lt;init&gt;(MasterFileSystem.java:131)
	at org.apache.hadoop.hbase.master.TestCatalogJanitor$MockMasterServices.&lt;init&gt;(TestCatalogJanitor.java:176)
	at org.apache.hadoop.hbase.master.TestCatalogJanitor.testCleanParent(TestCatalogJanitor.java:326)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:680)
</error>
    <system-err>2013-03-06 20:00:25,912 INFO  [pool-1-thread-1] hbase.ResourceChecker(147): before: master.TestCatalogJanitor#testCleanParent Thread=66, OpenFileDescriptor=158, MaxFileDescriptor=1000000, ConnectionCount=0
2013-03-06 20:00:25,923 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty(&quot;hadoop.log.dir&quot;) already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir so I do NOT create it in target/test-data/a6ff7264-9750-432b-9d64-1772e30616f4
2013-03-06 20:00:25,924 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.log.dir property value differs in configuration and system: Configuration=/Users/daidong/github/local/DominoHBase/hbase-server/../logs while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir Erasing configuration value by system value.
2013-03-06 20:00:25,924 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty(&quot;hadoop.tmp.dir&quot;) already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir so I do NOT create it in target/test-data/a6ff7264-9750-432b-9d64-1772e30616f4
2013-03-06 20:00:25,924 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.tmp.dir property value differs in configuration and system: Configuration=/tmp/hadoop-daidong while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir Erasing configuration value by system value.
2013-03-06 20:00:26,450 INFO  [pool-1-thread-1] master.SplitLogManager(179): timeout = 120000
2013-03-06 20:00:26,450 INFO  [pool-1-thread-1] master.SplitLogManager(180): unassigned timeout = 180000
2013-03-06 20:00:26,475 DEBUG [pool-1-thread-1] util.FSUtils(440): Created version file at file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/a6ff7264-9750-432b-9d64-1772e30616f4/testCleanParent with version=7
2013-03-06 20:00:26,500 DEBUG [pool-1-thread-1] util.FSUtils(569): Created cluster ID file at file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/a6ff7264-9750-432b-9d64-1772e30616f4/testCleanParent/hbase.id with ID: 827807c8-cddd-4b4d-9516-432c5b41e7a1
2013-03-06 20:00:26,544 INFO  [pool-1-thread-1] master.MasterFileSystem(444): BOOTSTRAP: creating ROOT and first META regions
2013-03-06 20:00:26,544 INFO  [pool-1-thread-1] regionserver.HRegion(3895): creating HRegion -ROOT- HTD == &apos;-ROOT-&apos;, {TABLE_ATTRIBUTES =&gt; {IS_META =&gt; &apos;true&apos;, IS_ROOT =&gt; &apos;true&apos;}}, {NAME =&gt; &apos;info&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;NONE&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, COMPRESSION =&gt; &apos;NONE&apos;, VERSIONS =&gt; &apos;10&apos;, TTL =&gt; &apos;2147483647&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, KEEP_DELETED_CELLS =&gt; &apos;false&apos;, BLOCKSIZE =&gt; &apos;8192&apos;, ENCODE_ON_DISK =&gt; &apos;true&apos;, IN_MEMORY =&gt; &apos;false&apos;, BLOCKCACHE =&gt; &apos;false&apos;} RootDir = file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/a6ff7264-9750-432b-9d64-1772e30616f4/testCleanParent Table name == -ROOT-
2013-03-06 20:00:26,545 INFO  [pool-1-thread-1] wal.FSHLog(333): HLog configuration: blocksize=32 MB, rollsize=30.4 MB, enabled=true, optionallogflushinternal=1000ms
2013-03-06 20:00:26,548 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2013-03-06 20:00:26,548 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(193): Path=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/a6ff7264-9750-432b-9d64-1772e30616f4/testCleanParent/-ROOT-/70236052/.logs/hlog.1362571226546, compression=false
2013-03-06 20:00:26,549 INFO  [pool-1-thread-1] wal.FSHLog(519):  for /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/a6ff7264-9750-432b-9d64-1772e30616f4/testCleanParent/-ROOT-/70236052/.logs/hlog.1362571226546
2013-03-06 20:00:26,549 INFO  [pool-1-thread-1] wal.FSHLog(409): FileSystem&apos;s output stream doesn&apos;t support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2013-03-06 20:00:26,550 DEBUG [pool-1-thread-1] regionserver.HRegion(495): Instantiated -ROOT-,,0.70236052
2013-03-06 20:00:26,550 DEBUG [pool-1-thread-1] util.FSUtils(165): Creating file=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/a6ff7264-9750-432b-9d64-1772e30616f4/testCleanParent/-ROOT-/70236052/.tmp/.regioninfo with permission=rwxrwxrwx
2013-03-06 20:00:26,555 INFO  [StoreOpenerThread--ROOT-,,0.70236052-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 20:00:26,556 INFO  [pool-1-thread-1] regionserver.HRegion(640): Onlined -ROOT-,,0.70236052; next sequenceid=1
2013-03-06 20:00:26,556 INFO  [pool-1-thread-1] regionserver.HRegion(3895): creating HRegion .META. HTD == &apos;.META.&apos;, {TABLE_ATTRIBUTES =&gt; {IS_META =&gt; &apos;true&apos;}}, {NAME =&gt; &apos;info&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;NONE&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, COMPRESSION =&gt; &apos;NONE&apos;, VERSIONS =&gt; &apos;10&apos;, TTL =&gt; &apos;2147483647&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, KEEP_DELETED_CELLS =&gt; &apos;false&apos;, BLOCKSIZE =&gt; &apos;8192&apos;, ENCODE_ON_DISK =&gt; &apos;true&apos;, IN_MEMORY =&gt; &apos;false&apos;, BLOCKCACHE =&gt; &apos;false&apos;} RootDir = file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/a6ff7264-9750-432b-9d64-1772e30616f4/testCleanParent Table name == .META.
2013-03-06 20:00:26,557 INFO  [pool-1-thread-1] wal.FSHLog(333): HLog configuration: blocksize=32 MB, rollsize=30.4 MB, enabled=true, optionallogflushinternal=1000ms
2013-03-06 20:00:26,559 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2013-03-06 20:00:26,559 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(193): Path=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/a6ff7264-9750-432b-9d64-1772e30616f4/testCleanParent/.META./1028785192/.logs/hlog.1362571226558, compression=false
2013-03-06 20:00:26,560 INFO  [pool-1-thread-1] wal.FSHLog(519):  for /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/a6ff7264-9750-432b-9d64-1772e30616f4/testCleanParent/.META./1028785192/.logs/hlog.1362571226558
2013-03-06 20:00:26,560 INFO  [pool-1-thread-1] wal.FSHLog(409): FileSystem&apos;s output stream doesn&apos;t support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2013-03-06 20:00:26,560 DEBUG [pool-1-thread-1] regionserver.HRegion(495): Instantiated .META.,,1.1028785192
2013-03-06 20:00:26,561 DEBUG [pool-1-thread-1] util.FSUtils(165): Creating file=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/a6ff7264-9750-432b-9d64-1772e30616f4/testCleanParent/.META./1028785192/.tmp/.regioninfo with permission=rwxrwxrwx
2013-03-06 20:00:26,565 INFO  [StoreOpenerThread-.META.,,1.1028785192-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 20:00:26,565 INFO  [pool-1-thread-1] regionserver.HRegion(640): Onlined .META.,,1.1028785192; next sequenceid=1
2013-03-06 20:00:26,567 DEBUG [pool-1-thread-1] regionserver.HRegion(2657): rollbackMemstore rolled back 2 keyvalues from start:0 to end:1
2013-03-06 20:00:26,570 INFO  [pool-1-thread-1] hbase.ResourceChecker(171): after: master.TestCatalogJanitor#testCleanParent Thread=69 (was 66)
Potentially hanging thread: mockserver.example.org,1234,-1.splitLogManagerTimeoutMonitor
	java.lang.Object.wait(Native Method)
	org.apache.hadoop.hbase.util.Sleeper.sleep(Sleeper.java:94)
	org.apache.hadoop.hbase.Chore.run(Chore.java:76)
	java.lang.Thread.run(Thread.java:680)
 - Thread LEAK? -, OpenFileDescriptor=162 (was 158) - OpenFileDescriptor LEAK? -, MaxFileDescriptor=1000000 (was 1000000), ConnectionCount=1 (was 0) - ConnectionCount LEAK? -
</system-err>
  </testcase>
  <testcase time="0.001" classname="org.apache.hadoop.hbase.master.TestCatalogJanitor" name="testParentCleanedEvenIfDaughterGoneFirst">
    <error type="java.lang.NullPointerException">java.lang.NullPointerException
	at org.apache.hadoop.hbase.trigger.LocalTriggerManage.containsTrigger(LocalTriggerManage.java:39)
	at org.apache.hadoop.hbase.regionserver.wal.WALDetection.checkDispatch(WALDetection.java:27)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.doWrite(FSHLog.java:1220)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.append(FSHLog.java:915)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.appendNoSync(FSHLog.java:937)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:2261)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2010)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:2465)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:2580)
	at org.apache.hadoop.hbase.regionserver.HRegion.addRegionToMETA(HRegion.java:4071)
	at org.apache.hadoop.hbase.master.MasterFileSystem.bootstrap(MasterFileSystem.java:461)
	at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:432)
	at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:147)
	at org.apache.hadoop.hbase.master.MasterFileSystem.&lt;init&gt;(MasterFileSystem.java:131)
	at org.apache.hadoop.hbase.master.TestCatalogJanitor$MockMasterServices.&lt;init&gt;(TestCatalogJanitor.java:176)
	at org.apache.hadoop.hbase.master.TestCatalogJanitor.parentWithSpecifiedEndKeyCleanedEvenIfDaughterGoneFirst(TestCatalogJanitor.java:403)
	at org.apache.hadoop.hbase.master.TestCatalogJanitor.testParentCleanedEvenIfDaughterGoneFirst(TestCatalogJanitor.java:373)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:680)
</error>
    <system-err>2013-03-06 20:00:26,572 INFO  [pool-1-thread-1] hbase.ResourceChecker(147): before: master.TestCatalogJanitor#testParentCleanedEvenIfDaughterGoneFirst Thread=69, OpenFileDescriptor=162, MaxFileDescriptor=1000000, ConnectionCount=1
2013-03-06 20:00:26,580 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty(&quot;hadoop.log.dir&quot;) already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir so I do NOT create it in target/test-data/d13f2ede-3fc9-4d05-ad1a-74e8e0fb1257
2013-03-06 20:00:26,580 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.log.dir property value differs in configuration and system: Configuration=/Users/daidong/github/local/DominoHBase/hbase-server/../logs while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir Erasing configuration value by system value.
2013-03-06 20:00:26,581 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty(&quot;hadoop.tmp.dir&quot;) already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir so I do NOT create it in target/test-data/d13f2ede-3fc9-4d05-ad1a-74e8e0fb1257
2013-03-06 20:00:26,581 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.tmp.dir property value differs in configuration and system: Configuration=/tmp/hadoop-daidong while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir Erasing configuration value by system value.
2013-03-06 20:00:26,583 INFO  [pool-1-thread-1] master.SplitLogManager(179): timeout = 120000
2013-03-06 20:00:26,583 INFO  [pool-1-thread-1] master.SplitLogManager(180): unassigned timeout = 180000
2013-03-06 20:00:26,593 DEBUG [pool-1-thread-1] util.FSUtils(440): Created version file at file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/d13f2ede-3fc9-4d05-ad1a-74e8e0fb1257/testParentCleanedEvenIfDaughterGoneFirst with version=7
2013-03-06 20:00:26,594 DEBUG [pool-1-thread-1] util.FSUtils(569): Created cluster ID file at file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/d13f2ede-3fc9-4d05-ad1a-74e8e0fb1257/testParentCleanedEvenIfDaughterGoneFirst/hbase.id with ID: d4b81c02-4da7-497f-9447-60d3b04e84a9
2013-03-06 20:00:26,596 INFO  [pool-1-thread-1] master.MasterFileSystem(444): BOOTSTRAP: creating ROOT and first META regions
2013-03-06 20:00:26,596 INFO  [pool-1-thread-1] regionserver.HRegion(3895): creating HRegion -ROOT- HTD == &apos;-ROOT-&apos;, {TABLE_ATTRIBUTES =&gt; {IS_META =&gt; &apos;true&apos;, IS_ROOT =&gt; &apos;true&apos;}}, {NAME =&gt; &apos;info&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;NONE&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, COMPRESSION =&gt; &apos;NONE&apos;, VERSIONS =&gt; &apos;10&apos;, TTL =&gt; &apos;2147483647&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, KEEP_DELETED_CELLS =&gt; &apos;false&apos;, BLOCKSIZE =&gt; &apos;8192&apos;, ENCODE_ON_DISK =&gt; &apos;true&apos;, IN_MEMORY =&gt; &apos;false&apos;, BLOCKCACHE =&gt; &apos;false&apos;} RootDir = file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/d13f2ede-3fc9-4d05-ad1a-74e8e0fb1257/testParentCleanedEvenIfDaughterGoneFirst Table name == -ROOT-
2013-03-06 20:00:26,597 INFO  [pool-1-thread-1] wal.FSHLog(333): HLog configuration: blocksize=32 MB, rollsize=30.4 MB, enabled=true, optionallogflushinternal=1000ms
2013-03-06 20:00:26,599 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2013-03-06 20:00:26,600 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(193): Path=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/d13f2ede-3fc9-4d05-ad1a-74e8e0fb1257/testParentCleanedEvenIfDaughterGoneFirst/-ROOT-/70236052/.logs/hlog.1362571226598, compression=false
2013-03-06 20:00:26,600 INFO  [pool-1-thread-1] wal.FSHLog(519):  for /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/d13f2ede-3fc9-4d05-ad1a-74e8e0fb1257/testParentCleanedEvenIfDaughterGoneFirst/-ROOT-/70236052/.logs/hlog.1362571226598
2013-03-06 20:00:26,600 INFO  [pool-1-thread-1] wal.FSHLog(409): FileSystem&apos;s output stream doesn&apos;t support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2013-03-06 20:00:26,601 DEBUG [pool-1-thread-1] regionserver.HRegion(495): Instantiated -ROOT-,,0.70236052
2013-03-06 20:00:26,602 DEBUG [pool-1-thread-1] util.FSUtils(165): Creating file=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/d13f2ede-3fc9-4d05-ad1a-74e8e0fb1257/testParentCleanedEvenIfDaughterGoneFirst/-ROOT-/70236052/.tmp/.regioninfo with permission=rwxrwxrwx
2013-03-06 20:00:26,614 INFO  [StoreOpenerThread--ROOT-,,0.70236052-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 20:00:26,615 INFO  [pool-1-thread-1] regionserver.HRegion(640): Onlined -ROOT-,,0.70236052; next sequenceid=1
2013-03-06 20:00:26,616 INFO  [pool-1-thread-1] regionserver.HRegion(3895): creating HRegion .META. HTD == &apos;.META.&apos;, {TABLE_ATTRIBUTES =&gt; {IS_META =&gt; &apos;true&apos;}}, {NAME =&gt; &apos;info&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;NONE&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, COMPRESSION =&gt; &apos;NONE&apos;, VERSIONS =&gt; &apos;10&apos;, TTL =&gt; &apos;2147483647&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, KEEP_DELETED_CELLS =&gt; &apos;false&apos;, BLOCKSIZE =&gt; &apos;8192&apos;, ENCODE_ON_DISK =&gt; &apos;true&apos;, IN_MEMORY =&gt; &apos;false&apos;, BLOCKCACHE =&gt; &apos;false&apos;} RootDir = file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/d13f2ede-3fc9-4d05-ad1a-74e8e0fb1257/testParentCleanedEvenIfDaughterGoneFirst Table name == .META.
2013-03-06 20:00:26,617 INFO  [pool-1-thread-1] wal.FSHLog(333): HLog configuration: blocksize=32 MB, rollsize=30.4 MB, enabled=true, optionallogflushinternal=1000ms
2013-03-06 20:00:26,619 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2013-03-06 20:00:26,621 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(193): Path=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/d13f2ede-3fc9-4d05-ad1a-74e8e0fb1257/testParentCleanedEvenIfDaughterGoneFirst/.META./1028785192/.logs/hlog.1362571226618, compression=false
2013-03-06 20:00:26,621 INFO  [pool-1-thread-1] wal.FSHLog(519):  for /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/d13f2ede-3fc9-4d05-ad1a-74e8e0fb1257/testParentCleanedEvenIfDaughterGoneFirst/.META./1028785192/.logs/hlog.1362571226618
2013-03-06 20:00:26,621 INFO  [pool-1-thread-1] wal.FSHLog(409): FileSystem&apos;s output stream doesn&apos;t support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2013-03-06 20:00:26,628 DEBUG [pool-1-thread-1] regionserver.HRegion(495): Instantiated .META.,,1.1028785192
2013-03-06 20:00:26,629 DEBUG [pool-1-thread-1] util.FSUtils(165): Creating file=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/d13f2ede-3fc9-4d05-ad1a-74e8e0fb1257/testParentCleanedEvenIfDaughterGoneFirst/.META./1028785192/.tmp/.regioninfo with permission=rwxrwxrwx
2013-03-06 20:00:26,637 INFO  [StoreOpenerThread-.META.,,1.1028785192-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 20:00:26,638 INFO  [pool-1-thread-1] regionserver.HRegion(640): Onlined .META.,,1.1028785192; next sequenceid=1
2013-03-06 20:00:26,639 DEBUG [pool-1-thread-1] regionserver.HRegion(2657): rollbackMemstore rolled back 2 keyvalues from start:0 to end:1
2013-03-06 20:00:26,643 INFO  [pool-1-thread-1] hbase.ResourceChecker(171): after: master.TestCatalogJanitor#testParentCleanedEvenIfDaughterGoneFirst Thread=73 (was 69)
Potentially hanging thread: StoreOpenerThread-.META.,,1.1028785192-1
	sun.misc.Unsafe.park(Native Method)
	java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:196)
	java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2025)
	java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:424)
	java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:945)
	java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
	java.lang.Thread.run(Thread.java:680)
 - Thread LEAK? -, OpenFileDescriptor=166 (was 162) - OpenFileDescriptor LEAK? -, MaxFileDescriptor=1000000 (was 1000000), ConnectionCount=1 (was 1)
</system-err>
  </testcase>
  <testcase time="0" classname="org.apache.hadoop.hbase.master.TestCatalogJanitor" name="testLastParentCleanedEvenIfDaughterGoneFirst">
    <error type="java.lang.NullPointerException">java.lang.NullPointerException
	at org.apache.hadoop.hbase.trigger.LocalTriggerManage.containsTrigger(LocalTriggerManage.java:39)
	at org.apache.hadoop.hbase.regionserver.wal.WALDetection.checkDispatch(WALDetection.java:27)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.doWrite(FSHLog.java:1220)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.append(FSHLog.java:915)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.appendNoSync(FSHLog.java:937)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:2261)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2010)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:2465)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:2580)
	at org.apache.hadoop.hbase.regionserver.HRegion.addRegionToMETA(HRegion.java:4071)
	at org.apache.hadoop.hbase.master.MasterFileSystem.bootstrap(MasterFileSystem.java:461)
	at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:432)
	at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:147)
	at org.apache.hadoop.hbase.master.MasterFileSystem.&lt;init&gt;(MasterFileSystem.java:131)
	at org.apache.hadoop.hbase.master.TestCatalogJanitor$MockMasterServices.&lt;init&gt;(TestCatalogJanitor.java:176)
	at org.apache.hadoop.hbase.master.TestCatalogJanitor.parentWithSpecifiedEndKeyCleanedEvenIfDaughterGoneFirst(TestCatalogJanitor.java:403)
	at org.apache.hadoop.hbase.master.TestCatalogJanitor.testLastParentCleanedEvenIfDaughterGoneFirst(TestCatalogJanitor.java:385)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:680)
</error>
    <system-err>2013-03-06 20:00:26,646 INFO  [pool-1-thread-1] hbase.ResourceChecker(147): before: master.TestCatalogJanitor#testLastParentCleanedEvenIfDaughterGoneFirst Thread=72, OpenFileDescriptor=166, MaxFileDescriptor=1000000, ConnectionCount=1
2013-03-06 20:00:26,655 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty(&quot;hadoop.log.dir&quot;) already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir so I do NOT create it in target/test-data/b08d36dd-a081-48df-b519-a24bec2d0330
2013-03-06 20:00:26,656 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.log.dir property value differs in configuration and system: Configuration=/Users/daidong/github/local/DominoHBase/hbase-server/../logs while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir Erasing configuration value by system value.
2013-03-06 20:00:26,656 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty(&quot;hadoop.tmp.dir&quot;) already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir so I do NOT create it in target/test-data/b08d36dd-a081-48df-b519-a24bec2d0330
2013-03-06 20:00:26,656 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.tmp.dir property value differs in configuration and system: Configuration=/tmp/hadoop-daidong while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir Erasing configuration value by system value.
2013-03-06 20:00:26,658 INFO  [pool-1-thread-1] master.SplitLogManager(179): timeout = 120000
2013-03-06 20:00:26,658 INFO  [pool-1-thread-1] master.SplitLogManager(180): unassigned timeout = 180000
2013-03-06 20:00:26,660 DEBUG [pool-1-thread-1] util.FSUtils(440): Created version file at file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/b08d36dd-a081-48df-b519-a24bec2d0330/testLastParentCleanedEvenIfDaughterGoneFirst with version=7
2013-03-06 20:00:26,662 DEBUG [pool-1-thread-1] util.FSUtils(569): Created cluster ID file at file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/b08d36dd-a081-48df-b519-a24bec2d0330/testLastParentCleanedEvenIfDaughterGoneFirst/hbase.id with ID: f760a795-5cad-4855-bb13-c5e204904537
2013-03-06 20:00:26,663 INFO  [pool-1-thread-1] master.MasterFileSystem(444): BOOTSTRAP: creating ROOT and first META regions
2013-03-06 20:00:26,664 INFO  [pool-1-thread-1] regionserver.HRegion(3895): creating HRegion -ROOT- HTD == &apos;-ROOT-&apos;, {TABLE_ATTRIBUTES =&gt; {IS_META =&gt; &apos;true&apos;, IS_ROOT =&gt; &apos;true&apos;}}, {NAME =&gt; &apos;info&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;NONE&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, COMPRESSION =&gt; &apos;NONE&apos;, VERSIONS =&gt; &apos;10&apos;, TTL =&gt; &apos;2147483647&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, KEEP_DELETED_CELLS =&gt; &apos;false&apos;, BLOCKSIZE =&gt; &apos;8192&apos;, ENCODE_ON_DISK =&gt; &apos;true&apos;, IN_MEMORY =&gt; &apos;false&apos;, BLOCKCACHE =&gt; &apos;false&apos;} RootDir = file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/b08d36dd-a081-48df-b519-a24bec2d0330/testLastParentCleanedEvenIfDaughterGoneFirst Table name == -ROOT-
2013-03-06 20:00:26,665 INFO  [pool-1-thread-1] wal.FSHLog(333): HLog configuration: blocksize=32 MB, rollsize=30.4 MB, enabled=true, optionallogflushinternal=1000ms
2013-03-06 20:00:26,667 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2013-03-06 20:00:26,668 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(193): Path=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/b08d36dd-a081-48df-b519-a24bec2d0330/testLastParentCleanedEvenIfDaughterGoneFirst/-ROOT-/70236052/.logs/hlog.1362571226666, compression=false
2013-03-06 20:00:26,669 INFO  [pool-1-thread-1] wal.FSHLog(519):  for /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/b08d36dd-a081-48df-b519-a24bec2d0330/testLastParentCleanedEvenIfDaughterGoneFirst/-ROOT-/70236052/.logs/hlog.1362571226666
2013-03-06 20:00:26,669 INFO  [pool-1-thread-1] wal.FSHLog(409): FileSystem&apos;s output stream doesn&apos;t support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2013-03-06 20:00:26,670 DEBUG [pool-1-thread-1] regionserver.HRegion(495): Instantiated -ROOT-,,0.70236052
2013-03-06 20:00:26,671 DEBUG [pool-1-thread-1] util.FSUtils(165): Creating file=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/b08d36dd-a081-48df-b519-a24bec2d0330/testLastParentCleanedEvenIfDaughterGoneFirst/-ROOT-/70236052/.tmp/.regioninfo with permission=rwxrwxrwx
2013-03-06 20:00:26,675 INFO  [StoreOpenerThread--ROOT-,,0.70236052-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 20:00:26,676 INFO  [pool-1-thread-1] regionserver.HRegion(640): Onlined -ROOT-,,0.70236052; next sequenceid=1
2013-03-06 20:00:26,677 INFO  [pool-1-thread-1] regionserver.HRegion(3895): creating HRegion .META. HTD == &apos;.META.&apos;, {TABLE_ATTRIBUTES =&gt; {IS_META =&gt; &apos;true&apos;}}, {NAME =&gt; &apos;info&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;NONE&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, COMPRESSION =&gt; &apos;NONE&apos;, VERSIONS =&gt; &apos;10&apos;, TTL =&gt; &apos;2147483647&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, KEEP_DELETED_CELLS =&gt; &apos;false&apos;, BLOCKSIZE =&gt; &apos;8192&apos;, ENCODE_ON_DISK =&gt; &apos;true&apos;, IN_MEMORY =&gt; &apos;false&apos;, BLOCKCACHE =&gt; &apos;false&apos;} RootDir = file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/b08d36dd-a081-48df-b519-a24bec2d0330/testLastParentCleanedEvenIfDaughterGoneFirst Table name == .META.
2013-03-06 20:00:26,677 INFO  [pool-1-thread-1] wal.FSHLog(333): HLog configuration: blocksize=32 MB, rollsize=30.4 MB, enabled=true, optionallogflushinternal=1000ms
2013-03-06 20:00:26,680 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2013-03-06 20:00:26,680 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(193): Path=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/b08d36dd-a081-48df-b519-a24bec2d0330/testLastParentCleanedEvenIfDaughterGoneFirst/.META./1028785192/.logs/hlog.1362571226678, compression=false
2013-03-06 20:00:26,681 INFO  [pool-1-thread-1] wal.FSHLog(519):  for /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/b08d36dd-a081-48df-b519-a24bec2d0330/testLastParentCleanedEvenIfDaughterGoneFirst/.META./1028785192/.logs/hlog.1362571226678
2013-03-06 20:00:26,681 INFO  [pool-1-thread-1] wal.FSHLog(409): FileSystem&apos;s output stream doesn&apos;t support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2013-03-06 20:00:26,686 DEBUG [pool-1-thread-1] regionserver.HRegion(495): Instantiated .META.,,1.1028785192
2013-03-06 20:00:26,686 DEBUG [pool-1-thread-1] util.FSUtils(165): Creating file=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/b08d36dd-a081-48df-b519-a24bec2d0330/testLastParentCleanedEvenIfDaughterGoneFirst/.META./1028785192/.tmp/.regioninfo with permission=rwxrwxrwx
2013-03-06 20:00:26,690 INFO  [StoreOpenerThread-.META.,,1.1028785192-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 20:00:26,691 INFO  [pool-1-thread-1] regionserver.HRegion(640): Onlined .META.,,1.1028785192; next sequenceid=1
2013-03-06 20:00:26,692 DEBUG [pool-1-thread-1] regionserver.HRegion(2657): rollbackMemstore rolled back 2 keyvalues from start:0 to end:1
2013-03-06 20:00:26,694 INFO  [pool-1-thread-1] hbase.ResourceChecker(171): after: master.TestCatalogJanitor#testLastParentCleanedEvenIfDaughterGoneFirst Thread=75 (was 72) - Thread LEAK? -, OpenFileDescriptor=170 (was 166) - OpenFileDescriptor LEAK? -, MaxFileDescriptor=1000000 (was 1000000), ConnectionCount=1 (was 1)
</system-err>
  </testcase>
  <testcase time="0.001" classname="org.apache.hadoop.hbase.master.TestCatalogJanitor" name="testScanDoesNotCleanRegionsWithExistingParents">
    <error type="java.lang.NullPointerException">java.lang.NullPointerException
	at org.apache.hadoop.hbase.trigger.LocalTriggerManage.containsTrigger(LocalTriggerManage.java:39)
	at org.apache.hadoop.hbase.regionserver.wal.WALDetection.checkDispatch(WALDetection.java:27)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.doWrite(FSHLog.java:1220)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.append(FSHLog.java:915)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.appendNoSync(FSHLog.java:937)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:2261)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2010)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:2465)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:2580)
	at org.apache.hadoop.hbase.regionserver.HRegion.addRegionToMETA(HRegion.java:4071)
	at org.apache.hadoop.hbase.master.MasterFileSystem.bootstrap(MasterFileSystem.java:461)
	at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:432)
	at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:147)
	at org.apache.hadoop.hbase.master.MasterFileSystem.&lt;init&gt;(MasterFileSystem.java:131)
	at org.apache.hadoop.hbase.master.TestCatalogJanitor$MockMasterServices.&lt;init&gt;(TestCatalogJanitor.java:176)
	at org.apache.hadoop.hbase.master.TestCatalogJanitor.testScanDoesNotCleanRegionsWithExistingParents(TestCatalogJanitor.java:505)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:680)
</error>
    <system-err>2013-03-06 20:00:26,696 INFO  [pool-1-thread-1] hbase.ResourceChecker(147): before: master.TestCatalogJanitor#testScanDoesNotCleanRegionsWithExistingParents Thread=75, OpenFileDescriptor=170, MaxFileDescriptor=1000000, ConnectionCount=1
2013-03-06 20:00:26,705 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty(&quot;hadoop.log.dir&quot;) already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir so I do NOT create it in target/test-data/339ec846-e59d-43d0-9ffb-dc3636849583
2013-03-06 20:00:26,706 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.log.dir property value differs in configuration and system: Configuration=/Users/daidong/github/local/DominoHBase/hbase-server/../logs while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir Erasing configuration value by system value.
2013-03-06 20:00:26,706 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty(&quot;hadoop.tmp.dir&quot;) already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir so I do NOT create it in target/test-data/339ec846-e59d-43d0-9ffb-dc3636849583
2013-03-06 20:00:26,706 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.tmp.dir property value differs in configuration and system: Configuration=/tmp/hadoop-daidong while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir Erasing configuration value by system value.
2013-03-06 20:00:26,708 INFO  [pool-1-thread-1] master.SplitLogManager(179): timeout = 120000
2013-03-06 20:00:26,708 INFO  [pool-1-thread-1] master.SplitLogManager(180): unassigned timeout = 180000
2013-03-06 20:00:26,710 DEBUG [pool-1-thread-1] util.FSUtils(440): Created version file at file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/339ec846-e59d-43d0-9ffb-dc3636849583/testScanDoesNotCleanRegionsWithExistingParents with version=7
2013-03-06 20:00:26,720 DEBUG [pool-1-thread-1] util.FSUtils(569): Created cluster ID file at file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/339ec846-e59d-43d0-9ffb-dc3636849583/testScanDoesNotCleanRegionsWithExistingParents/hbase.id with ID: 12038e99-b835-40b0-a394-0fd4e3f3525c
2013-03-06 20:00:26,721 INFO  [pool-1-thread-1] master.MasterFileSystem(444): BOOTSTRAP: creating ROOT and first META regions
2013-03-06 20:00:26,721 INFO  [pool-1-thread-1] regionserver.HRegion(3895): creating HRegion -ROOT- HTD == &apos;-ROOT-&apos;, {TABLE_ATTRIBUTES =&gt; {IS_META =&gt; &apos;true&apos;, IS_ROOT =&gt; &apos;true&apos;}}, {NAME =&gt; &apos;info&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;NONE&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, COMPRESSION =&gt; &apos;NONE&apos;, VERSIONS =&gt; &apos;10&apos;, TTL =&gt; &apos;2147483647&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, KEEP_DELETED_CELLS =&gt; &apos;false&apos;, BLOCKSIZE =&gt; &apos;8192&apos;, ENCODE_ON_DISK =&gt; &apos;true&apos;, IN_MEMORY =&gt; &apos;false&apos;, BLOCKCACHE =&gt; &apos;false&apos;} RootDir = file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/339ec846-e59d-43d0-9ffb-dc3636849583/testScanDoesNotCleanRegionsWithExistingParents Table name == -ROOT-
2013-03-06 20:00:26,722 INFO  [pool-1-thread-1] wal.FSHLog(333): HLog configuration: blocksize=32 MB, rollsize=30.4 MB, enabled=true, optionallogflushinternal=1000ms
2013-03-06 20:00:26,725 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2013-03-06 20:00:26,725 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(193): Path=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/339ec846-e59d-43d0-9ffb-dc3636849583/testScanDoesNotCleanRegionsWithExistingParents/-ROOT-/70236052/.logs/hlog.1362571226723, compression=false
2013-03-06 20:00:26,725 INFO  [pool-1-thread-1] wal.FSHLog(519):  for /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/339ec846-e59d-43d0-9ffb-dc3636849583/testScanDoesNotCleanRegionsWithExistingParents/-ROOT-/70236052/.logs/hlog.1362571226723
2013-03-06 20:00:26,725 INFO  [pool-1-thread-1] wal.FSHLog(409): FileSystem&apos;s output stream doesn&apos;t support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2013-03-06 20:00:26,726 DEBUG [pool-1-thread-1] regionserver.HRegion(495): Instantiated -ROOT-,,0.70236052
2013-03-06 20:00:26,726 DEBUG [pool-1-thread-1] util.FSUtils(165): Creating file=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/339ec846-e59d-43d0-9ffb-dc3636849583/testScanDoesNotCleanRegionsWithExistingParents/-ROOT-/70236052/.tmp/.regioninfo with permission=rwxrwxrwx
2013-03-06 20:00:26,731 INFO  [StoreOpenerThread--ROOT-,,0.70236052-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 20:00:26,733 INFO  [pool-1-thread-1] regionserver.HRegion(640): Onlined -ROOT-,,0.70236052; next sequenceid=1
2013-03-06 20:00:26,733 INFO  [pool-1-thread-1] regionserver.HRegion(3895): creating HRegion .META. HTD == &apos;.META.&apos;, {TABLE_ATTRIBUTES =&gt; {IS_META =&gt; &apos;true&apos;}}, {NAME =&gt; &apos;info&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;NONE&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, COMPRESSION =&gt; &apos;NONE&apos;, VERSIONS =&gt; &apos;10&apos;, TTL =&gt; &apos;2147483647&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, KEEP_DELETED_CELLS =&gt; &apos;false&apos;, BLOCKSIZE =&gt; &apos;8192&apos;, ENCODE_ON_DISK =&gt; &apos;true&apos;, IN_MEMORY =&gt; &apos;false&apos;, BLOCKCACHE =&gt; &apos;false&apos;} RootDir = file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/339ec846-e59d-43d0-9ffb-dc3636849583/testScanDoesNotCleanRegionsWithExistingParents Table name == .META.
2013-03-06 20:00:26,734 INFO  [pool-1-thread-1] wal.FSHLog(333): HLog configuration: blocksize=32 MB, rollsize=30.4 MB, enabled=true, optionallogflushinternal=1000ms
2013-03-06 20:00:26,736 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2013-03-06 20:00:26,736 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(193): Path=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/339ec846-e59d-43d0-9ffb-dc3636849583/testScanDoesNotCleanRegionsWithExistingParents/.META./1028785192/.logs/hlog.1362571226735, compression=false
2013-03-06 20:00:26,737 INFO  [pool-1-thread-1] wal.FSHLog(519):  for /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/339ec846-e59d-43d0-9ffb-dc3636849583/testScanDoesNotCleanRegionsWithExistingParents/.META./1028785192/.logs/hlog.1362571226735
2013-03-06 20:00:26,737 INFO  [pool-1-thread-1] wal.FSHLog(409): FileSystem&apos;s output stream doesn&apos;t support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2013-03-06 20:00:26,737 DEBUG [pool-1-thread-1] regionserver.HRegion(495): Instantiated .META.,,1.1028785192
2013-03-06 20:00:26,738 DEBUG [pool-1-thread-1] util.FSUtils(165): Creating file=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/339ec846-e59d-43d0-9ffb-dc3636849583/testScanDoesNotCleanRegionsWithExistingParents/.META./1028785192/.tmp/.regioninfo with permission=rwxrwxrwx
2013-03-06 20:00:26,742 INFO  [StoreOpenerThread-.META.,,1.1028785192-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 20:00:26,743 INFO  [pool-1-thread-1] regionserver.HRegion(640): Onlined .META.,,1.1028785192; next sequenceid=1
2013-03-06 20:00:26,744 DEBUG [pool-1-thread-1] regionserver.HRegion(2657): rollbackMemstore rolled back 2 keyvalues from start:0 to end:1
2013-03-06 20:00:26,747 INFO  [pool-1-thread-1] hbase.ResourceChecker(171): after: master.TestCatalogJanitor#testScanDoesNotCleanRegionsWithExistingParents Thread=78 (was 75) - Thread LEAK? -, OpenFileDescriptor=174 (was 170) - OpenFileDescriptor LEAK? -, MaxFileDescriptor=1000000 (was 1000000), ConnectionCount=1 (was 1)
</system-err>
  </testcase>
  <testcase time="0" classname="org.apache.hadoop.hbase.master.TestCatalogJanitor" name="testArchiveOldRegion">
    <error type="java.lang.NullPointerException">java.lang.NullPointerException
	at org.apache.hadoop.hbase.trigger.LocalTriggerManage.containsTrigger(LocalTriggerManage.java:39)
	at org.apache.hadoop.hbase.regionserver.wal.WALDetection.checkDispatch(WALDetection.java:27)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.doWrite(FSHLog.java:1220)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.append(FSHLog.java:915)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.appendNoSync(FSHLog.java:937)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:2261)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2010)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:2465)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:2580)
	at org.apache.hadoop.hbase.regionserver.HRegion.addRegionToMETA(HRegion.java:4071)
	at org.apache.hadoop.hbase.master.MasterFileSystem.bootstrap(MasterFileSystem.java:461)
	at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:432)
	at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:147)
	at org.apache.hadoop.hbase.master.MasterFileSystem.&lt;init&gt;(MasterFileSystem.java:131)
	at org.apache.hadoop.hbase.master.TestCatalogJanitor$MockMasterServices.&lt;init&gt;(TestCatalogJanitor.java:176)
	at org.apache.hadoop.hbase.master.TestCatalogJanitor.testArchiveOldRegion(TestCatalogJanitor.java:571)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:680)
</error>
    <system-err>2013-03-06 20:00:26,749 INFO  [pool-1-thread-1] hbase.ResourceChecker(147): before: master.TestCatalogJanitor#testArchiveOldRegion Thread=78, OpenFileDescriptor=174, MaxFileDescriptor=1000000, ConnectionCount=1
2013-03-06 20:00:26,757 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty(&quot;hadoop.log.dir&quot;) already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir so I do NOT create it in target/test-data/4b6db0ea-6636-4735-935d-4cb45a5c9acd
2013-03-06 20:00:26,757 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.log.dir property value differs in configuration and system: Configuration=/Users/daidong/github/local/DominoHBase/hbase-server/../logs while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir Erasing configuration value by system value.
2013-03-06 20:00:26,758 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty(&quot;hadoop.tmp.dir&quot;) already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir so I do NOT create it in target/test-data/4b6db0ea-6636-4735-935d-4cb45a5c9acd
2013-03-06 20:00:26,758 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.tmp.dir property value differs in configuration and system: Configuration=/tmp/hadoop-daidong while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir Erasing configuration value by system value.
2013-03-06 20:00:26,759 INFO  [pool-1-thread-1] master.SplitLogManager(179): timeout = 120000
2013-03-06 20:00:26,760 INFO  [pool-1-thread-1] master.SplitLogManager(180): unassigned timeout = 180000
2013-03-06 20:00:26,761 DEBUG [pool-1-thread-1] util.FSUtils(440): Created version file at file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/4b6db0ea-6636-4735-935d-4cb45a5c9acd/testCleanParent with version=7
2013-03-06 20:00:26,763 DEBUG [pool-1-thread-1] util.FSUtils(569): Created cluster ID file at file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/4b6db0ea-6636-4735-935d-4cb45a5c9acd/testCleanParent/hbase.id with ID: 755e9ef7-46c6-41e5-8767-fcf8c45cca90
2013-03-06 20:00:26,764 INFO  [pool-1-thread-1] master.MasterFileSystem(444): BOOTSTRAP: creating ROOT and first META regions
2013-03-06 20:00:26,764 INFO  [pool-1-thread-1] regionserver.HRegion(3895): creating HRegion -ROOT- HTD == &apos;-ROOT-&apos;, {TABLE_ATTRIBUTES =&gt; {IS_META =&gt; &apos;true&apos;, IS_ROOT =&gt; &apos;true&apos;}}, {NAME =&gt; &apos;info&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;NONE&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, COMPRESSION =&gt; &apos;NONE&apos;, VERSIONS =&gt; &apos;10&apos;, TTL =&gt; &apos;2147483647&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, KEEP_DELETED_CELLS =&gt; &apos;false&apos;, BLOCKSIZE =&gt; &apos;8192&apos;, ENCODE_ON_DISK =&gt; &apos;true&apos;, IN_MEMORY =&gt; &apos;false&apos;, BLOCKCACHE =&gt; &apos;false&apos;} RootDir = file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/4b6db0ea-6636-4735-935d-4cb45a5c9acd/testCleanParent Table name == -ROOT-
2013-03-06 20:00:26,765 INFO  [pool-1-thread-1] wal.FSHLog(333): HLog configuration: blocksize=32 MB, rollsize=30.4 MB, enabled=true, optionallogflushinternal=1000ms
2013-03-06 20:00:26,767 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2013-03-06 20:00:26,767 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(193): Path=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/4b6db0ea-6636-4735-935d-4cb45a5c9acd/testCleanParent/-ROOT-/70236052/.logs/hlog.1362571226766, compression=false
2013-03-06 20:00:26,767 INFO  [pool-1-thread-1] wal.FSHLog(519):  for /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/4b6db0ea-6636-4735-935d-4cb45a5c9acd/testCleanParent/-ROOT-/70236052/.logs/hlog.1362571226766
2013-03-06 20:00:26,768 INFO  [pool-1-thread-1] wal.FSHLog(409): FileSystem&apos;s output stream doesn&apos;t support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2013-03-06 20:00:26,770 DEBUG [pool-1-thread-1] regionserver.HRegion(495): Instantiated -ROOT-,,0.70236052
2013-03-06 20:00:26,770 DEBUG [pool-1-thread-1] util.FSUtils(165): Creating file=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/4b6db0ea-6636-4735-935d-4cb45a5c9acd/testCleanParent/-ROOT-/70236052/.tmp/.regioninfo with permission=rwxrwxrwx
2013-03-06 20:00:26,775 INFO  [StoreOpenerThread--ROOT-,,0.70236052-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 20:00:26,777 INFO  [pool-1-thread-1] regionserver.HRegion(640): Onlined -ROOT-,,0.70236052; next sequenceid=1
2013-03-06 20:00:26,777 INFO  [pool-1-thread-1] regionserver.HRegion(3895): creating HRegion .META. HTD == &apos;.META.&apos;, {TABLE_ATTRIBUTES =&gt; {IS_META =&gt; &apos;true&apos;}}, {NAME =&gt; &apos;info&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;NONE&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, COMPRESSION =&gt; &apos;NONE&apos;, VERSIONS =&gt; &apos;10&apos;, TTL =&gt; &apos;2147483647&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, KEEP_DELETED_CELLS =&gt; &apos;false&apos;, BLOCKSIZE =&gt; &apos;8192&apos;, ENCODE_ON_DISK =&gt; &apos;true&apos;, IN_MEMORY =&gt; &apos;false&apos;, BLOCKCACHE =&gt; &apos;false&apos;} RootDir = file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/4b6db0ea-6636-4735-935d-4cb45a5c9acd/testCleanParent Table name == .META.
2013-03-06 20:00:26,778 INFO  [pool-1-thread-1] wal.FSHLog(333): HLog configuration: blocksize=32 MB, rollsize=30.4 MB, enabled=true, optionallogflushinternal=1000ms
2013-03-06 20:00:26,780 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2013-03-06 20:00:26,780 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(193): Path=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/4b6db0ea-6636-4735-935d-4cb45a5c9acd/testCleanParent/.META./1028785192/.logs/hlog.1362571226779, compression=false
2013-03-06 20:00:26,781 INFO  [pool-1-thread-1] wal.FSHLog(519):  for /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/4b6db0ea-6636-4735-935d-4cb45a5c9acd/testCleanParent/.META./1028785192/.logs/hlog.1362571226779
2013-03-06 20:00:26,781 INFO  [pool-1-thread-1] wal.FSHLog(409): FileSystem&apos;s output stream doesn&apos;t support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2013-03-06 20:00:26,782 DEBUG [pool-1-thread-1] regionserver.HRegion(495): Instantiated .META.,,1.1028785192
2013-03-06 20:00:26,782 DEBUG [pool-1-thread-1] util.FSUtils(165): Creating file=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/4b6db0ea-6636-4735-935d-4cb45a5c9acd/testCleanParent/.META./1028785192/.tmp/.regioninfo with permission=rwxrwxrwx
2013-03-06 20:00:26,786 INFO  [StoreOpenerThread-.META.,,1.1028785192-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 20:00:26,787 INFO  [pool-1-thread-1] regionserver.HRegion(640): Onlined .META.,,1.1028785192; next sequenceid=1
2013-03-06 20:00:26,788 DEBUG [pool-1-thread-1] regionserver.HRegion(2657): rollbackMemstore rolled back 2 keyvalues from start:0 to end:1
2013-03-06 20:00:26,816 INFO  [pool-1-thread-1] hbase.ResourceChecker(171): after: master.TestCatalogJanitor#testArchiveOldRegion Thread=81 (was 78) - Thread LEAK? -, OpenFileDescriptor=178 (was 174) - OpenFileDescriptor LEAK? -, MaxFileDescriptor=1000000 (was 1000000), ConnectionCount=1 (was 1)
</system-err>
  </testcase>
  <testcase time="0.001" classname="org.apache.hadoop.hbase.master.TestCatalogJanitor" name="testDuplicateHFileResolution">
    <error type="java.lang.NullPointerException">java.lang.NullPointerException
	at org.apache.hadoop.hbase.trigger.LocalTriggerManage.containsTrigger(LocalTriggerManage.java:39)
	at org.apache.hadoop.hbase.regionserver.wal.WALDetection.checkDispatch(WALDetection.java:27)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.doWrite(FSHLog.java:1220)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.append(FSHLog.java:915)
	at org.apache.hadoop.hbase.regionserver.wal.FSHLog.appendNoSync(FSHLog.java:937)
	at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.java:2261)
	at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.java:2010)
	at org.apache.hadoop.hbase.regionserver.HRegion.doBatchMutate(HRegion.java:2465)
	at org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:2580)
	at org.apache.hadoop.hbase.regionserver.HRegion.addRegionToMETA(HRegion.java:4071)
	at org.apache.hadoop.hbase.master.MasterFileSystem.bootstrap(MasterFileSystem.java:461)
	at org.apache.hadoop.hbase.master.MasterFileSystem.checkRootDir(MasterFileSystem.java:432)
	at org.apache.hadoop.hbase.master.MasterFileSystem.createInitialFileSystemLayout(MasterFileSystem.java:147)
	at org.apache.hadoop.hbase.master.MasterFileSystem.&lt;init&gt;(MasterFileSystem.java:131)
	at org.apache.hadoop.hbase.master.TestCatalogJanitor$MockMasterServices.&lt;init&gt;(TestCatalogJanitor.java:176)
	at org.apache.hadoop.hbase.master.TestCatalogJanitor.testDuplicateHFileResolution(TestCatalogJanitor.java:652)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:680)
</error>
    <system-err>2013-03-06 20:00:26,818 INFO  [pool-1-thread-1] hbase.ResourceChecker(147): before: master.TestCatalogJanitor#testDuplicateHFileResolution Thread=81, OpenFileDescriptor=178, MaxFileDescriptor=1000000, ConnectionCount=1
2013-03-06 20:00:26,827 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty(&quot;hadoop.log.dir&quot;) already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir so I do NOT create it in target/test-data/337a9c35-48a0-423f-8e68-e494cd1a50d2
2013-03-06 20:00:26,827 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.log.dir property value differs in configuration and system: Configuration=/Users/daidong/github/local/DominoHBase/hbase-server/../logs while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-log-dir Erasing configuration value by system value.
2013-03-06 20:00:26,827 INFO  [pool-1-thread-1] hbase.HBaseTestingUtility(291): System.getProperty(&quot;hadoop.tmp.dir&quot;) already set to: /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir so I do NOT create it in target/test-data/337a9c35-48a0-423f-8e68-e494cd1a50d2
2013-03-06 20:00:26,827 WARN  [pool-1-thread-1] hbase.HBaseTestingUtility(295): hadoop.tmp.dir property value differs in configuration and system: Configuration=/tmp/hadoop-daidong while System=/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/c7e3b3bf-66f3-482b-9613-8cbfd1163ed8/hadoop-tmp-dir Erasing configuration value by system value.
2013-03-06 20:00:26,829 INFO  [pool-1-thread-1] master.SplitLogManager(179): timeout = 120000
2013-03-06 20:00:26,830 INFO  [pool-1-thread-1] master.SplitLogManager(180): unassigned timeout = 180000
2013-03-06 20:00:26,832 DEBUG [pool-1-thread-1] util.FSUtils(440): Created version file at file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/337a9c35-48a0-423f-8e68-e494cd1a50d2/testCleanParent with version=7
2013-03-06 20:00:26,833 DEBUG [pool-1-thread-1] util.FSUtils(569): Created cluster ID file at file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/337a9c35-48a0-423f-8e68-e494cd1a50d2/testCleanParent/hbase.id with ID: 16635b0f-bbf8-4c3e-8f2a-02d5b1817b6f
2013-03-06 20:00:26,834 INFO  [pool-1-thread-1] master.MasterFileSystem(444): BOOTSTRAP: creating ROOT and first META regions
2013-03-06 20:00:26,834 INFO  [pool-1-thread-1] regionserver.HRegion(3895): creating HRegion -ROOT- HTD == &apos;-ROOT-&apos;, {TABLE_ATTRIBUTES =&gt; {IS_META =&gt; &apos;true&apos;, IS_ROOT =&gt; &apos;true&apos;}}, {NAME =&gt; &apos;info&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;NONE&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, COMPRESSION =&gt; &apos;NONE&apos;, VERSIONS =&gt; &apos;10&apos;, TTL =&gt; &apos;2147483647&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, KEEP_DELETED_CELLS =&gt; &apos;false&apos;, BLOCKSIZE =&gt; &apos;8192&apos;, ENCODE_ON_DISK =&gt; &apos;true&apos;, IN_MEMORY =&gt; &apos;false&apos;, BLOCKCACHE =&gt; &apos;false&apos;} RootDir = file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/337a9c35-48a0-423f-8e68-e494cd1a50d2/testCleanParent Table name == -ROOT-
2013-03-06 20:00:26,835 INFO  [pool-1-thread-1] wal.FSHLog(333): HLog configuration: blocksize=32 MB, rollsize=30.4 MB, enabled=true, optionallogflushinternal=1000ms
2013-03-06 20:00:26,837 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2013-03-06 20:00:26,838 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(193): Path=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/337a9c35-48a0-423f-8e68-e494cd1a50d2/testCleanParent/-ROOT-/70236052/.logs/hlog.1362571226836, compression=false
2013-03-06 20:00:26,838 INFO  [pool-1-thread-1] wal.FSHLog(519):  for /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/337a9c35-48a0-423f-8e68-e494cd1a50d2/testCleanParent/-ROOT-/70236052/.logs/hlog.1362571226836
2013-03-06 20:00:26,838 INFO  [pool-1-thread-1] wal.FSHLog(409): FileSystem&apos;s output stream doesn&apos;t support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2013-03-06 20:00:26,840 DEBUG [pool-1-thread-1] regionserver.HRegion(495): Instantiated -ROOT-,,0.70236052
2013-03-06 20:00:26,841 DEBUG [pool-1-thread-1] util.FSUtils(165): Creating file=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/337a9c35-48a0-423f-8e68-e494cd1a50d2/testCleanParent/-ROOT-/70236052/.tmp/.regioninfo with permission=rwxrwxrwx
2013-03-06 20:00:26,847 INFO  [StoreOpenerThread--ROOT-,,0.70236052-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 20:00:26,847 INFO  [pool-1-thread-1] regionserver.HRegion(640): Onlined -ROOT-,,0.70236052; next sequenceid=1
2013-03-06 20:00:26,848 INFO  [pool-1-thread-1] regionserver.HRegion(3895): creating HRegion .META. HTD == &apos;.META.&apos;, {TABLE_ATTRIBUTES =&gt; {IS_META =&gt; &apos;true&apos;}}, {NAME =&gt; &apos;info&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, BLOOMFILTER =&gt; &apos;NONE&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, COMPRESSION =&gt; &apos;NONE&apos;, VERSIONS =&gt; &apos;10&apos;, TTL =&gt; &apos;2147483647&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, KEEP_DELETED_CELLS =&gt; &apos;false&apos;, BLOCKSIZE =&gt; &apos;8192&apos;, ENCODE_ON_DISK =&gt; &apos;true&apos;, IN_MEMORY =&gt; &apos;false&apos;, BLOCKCACHE =&gt; &apos;false&apos;} RootDir = file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/337a9c35-48a0-423f-8e68-e494cd1a50d2/testCleanParent Table name == .META.
2013-03-06 20:00:26,849 INFO  [pool-1-thread-1] wal.FSHLog(333): HLog configuration: blocksize=32 MB, rollsize=30.4 MB, enabled=true, optionallogflushinternal=1000ms
2013-03-06 20:00:26,851 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(189): using new createWriter -- HADOOP-6840
2013-03-06 20:00:26,851 DEBUG [pool-1-thread-1] wal.SequenceFileLogWriter(193): Path=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/337a9c35-48a0-423f-8e68-e494cd1a50d2/testCleanParent/.META./1028785192/.logs/hlog.1362571226849, compression=false
2013-03-06 20:00:26,851 INFO  [pool-1-thread-1] wal.FSHLog(519):  for /Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/337a9c35-48a0-423f-8e68-e494cd1a50d2/testCleanParent/.META./1028785192/.logs/hlog.1362571226849
2013-03-06 20:00:26,852 INFO  [pool-1-thread-1] wal.FSHLog(409): FileSystem&apos;s output stream doesn&apos;t support getNumCurrentReplicas; --HDFS-826 not available; fsOut=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer
2013-03-06 20:00:26,852 DEBUG [pool-1-thread-1] regionserver.HRegion(495): Instantiated .META.,,1.1028785192
2013-03-06 20:00:26,853 DEBUG [pool-1-thread-1] util.FSUtils(165): Creating file=file:/Users/daidong/github/local/DominoHBase/hbase-server/target/test-data/337a9c35-48a0-423f-8e68-e494cd1a50d2/testCleanParent/.META./1028785192/.tmp/.regioninfo with permission=rwxrwxrwx
2013-03-06 20:00:26,856 INFO  [StoreOpenerThread-.META.,,1.1028785192-1] compactions.CompactionConfiguration(97): Compaction configuration size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; off-peak hours -1--1; throttle point 2684354560; delete expired; major period 86400000, major jitter 0.200000
2013-03-06 20:00:26,857 INFO  [pool-1-thread-1] regionserver.HRegion(640): Onlined .META.,,1.1028785192; next sequenceid=1
2013-03-06 20:00:26,858 DEBUG [pool-1-thread-1] regionserver.HRegion(2657): rollbackMemstore rolled back 2 keyvalues from start:0 to end:1
2013-03-06 20:00:26,861 INFO  [pool-1-thread-1] hbase.ResourceChecker(171): after: master.TestCatalogJanitor#testDuplicateHFileResolution Thread=84 (was 81) - Thread LEAK? -, OpenFileDescriptor=182 (was 178) - OpenFileDescriptor LEAK? -, MaxFileDescriptor=1000000 (was 1000000), ConnectionCount=1 (was 1)
</system-err>
  </testcase>
</testsuite>